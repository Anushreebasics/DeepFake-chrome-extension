{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVc9M7XzPcN1wnHWFsiwH8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gilhotraapoorva/DF/blob/main/finalised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "CS4cvJmfKEK2",
        "outputId": "485cbdec-351a-4c17-c0ef-4243d5fbad13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-581fe7f7-c16b-4c70-9653-17b4751081eb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-581fe7f7-c16b-4c70-9653-17b4751081eb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle (2).json to kaggle (2).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (2).json': b'{\"username\":\"apoorvaaaaaa\",\"key\":\"d66784d4565981100258ecf8a750e6a2\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey2yv_KUKI0p",
        "outputId": "49f0f113-b587-40fd-f0b1-b64edc599b5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.7 / client 1.5.16)\n",
            "ref                                                        title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "---------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "sudarshan24byte/online-food-dataset                        Online Food Dataset                                  3KB  2024-03-02 18:50:30          14073        279  0.9411765        \n",
            "bhavikjikadara/student-study-performance                   Student Study Performance                            9KB  2024-03-07 06:14:09           7323        109  1.0              \n",
            "lovishbansal123/sales-of-a-supermarket                     Sales of a Supermarket                              36KB  2024-03-26 12:38:06           1277         27  1.0              \n",
            "syedanwarafridi/vehicle-sales-data                         Vehicle Sales Data                                  19MB  2024-02-21 20:16:17          21968        367  1.0              \n",
            "jasmeet0516/largest-companies-in-world                     Largest Companies in World                          47KB  2024-03-26 15:54:47            653         27  1.0              \n",
            "sukhmandeepsinghbrar/total-worldwide-passenger-cars-sales  Total Worldwide Passenger Cars Sales                 8KB  2024-03-25 16:32:42            806         29  1.0              \n",
            "kanchana1990/world-air-quality-data-2024-updated           World Air Quality Data 2024 (Updated)                2MB  2024-03-25 15:10:07           1331         37  1.0              \n",
            "sahirmaharajj/fuel-economy                                 Vehicle Fuel Economy                                 1MB  2024-03-20 18:27:18           1211         25  1.0              \n",
            "bhavikjikadara/mental-health-dataset                       Mental Health Dataset                                2MB  2024-03-18 06:05:16           1987         40  1.0              \n",
            "julianoorlandi/spotify-top-songs-and-audio-features        Spotify Top Songs and Audio Features               526KB  2024-03-18 12:49:50           2101         42  1.0              \n",
            "arnavvvvv/spotify-music                                    Top Spotify Songs                                   47KB  2024-03-06 05:20:29           7157         93  1.0              \n",
            "nbroad/gemma-rewrite-nbroad                                gemma-rewrite-nbroad                                 8MB  2024-03-03 04:52:39           1085         81  1.0              \n",
            "tarunrm09/climate-change-indicators                        Climate change Indicators                           34KB  2024-02-22 08:53:54          10322        187  1.0              \n",
            "ronaldonyango/global-suicide-rates-1990-to-2022            Suicide Rates & Socioeconomic Factors (1990 - 22)    2MB  2024-03-14 14:30:20           2650         37  1.0              \n",
            "nartaa/features-head-starter-models                        Features+Head Starter Models                         3GB  2024-03-26 11:32:50            400         30  1.0              \n",
            "nagajyothidakka/covid-19-global-dataset                    COVID-19 GLOBAL-Dataset                             10KB  2024-03-09 16:54:05           1269         36  0.9411765        \n",
            "thesnak/stock-market-analysis                              Stock Market Analysis                                6KB  2024-03-21 20:52:55            943         33  1.0              \n",
            "mexwell/us-colleges-and-universities                       🏫 US Colleges and Universities                     933KB  2024-03-19 14:21:05            680         21  1.0              \n",
            "rahulvyasm/medical-insurance-cost-prediction               Medical Insurance Cost Prediction                   32KB  2024-03-14 18:23:22           1416         30  0.9411765        \n",
            "mexwell/student-scores                                     🎓 Student Scores                                    62KB  2024-03-05 10:08:50           1643         30  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c deepfake-detection-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiOE3jPeKoaL",
        "outputId": "85a61151-ec28-4885-ac5c-d289c3a2f35f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading deepfake-detection-challenge.zip to /content\n",
            "100% 4.13G/4.13G [00:45<00:00, 160MB/s]\n",
            "100% 4.13G/4.13G [00:45<00:00, 97.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir train"
      ],
      "metadata": {
        "id": "m--SdRv8KtQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip deepfake-detection-challenge.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR6KKqNyKu3L",
        "outputId": "5418d890-70b2-4d5f-df02-6213b8d2af2f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  deepfake-detection-challenge.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test_videos/aassnaulhq.mp4  \n",
            "  inflating: test_videos/aayfryxljh.mp4  \n",
            "  inflating: test_videos/acazlolrpz.mp4  \n",
            "  inflating: test_videos/adohdulfwb.mp4  \n",
            "  inflating: test_videos/ahjnxtiamx.mp4  \n",
            "  inflating: test_videos/ajiyrjfyzp.mp4  \n",
            "  inflating: test_videos/aktnlyqpah.mp4  \n",
            "  inflating: test_videos/alrtntfxtd.mp4  \n",
            "  inflating: test_videos/aomqqjipcp.mp4  \n",
            "  inflating: test_videos/apedduehoy.mp4  \n",
            "  inflating: test_videos/apvzjkvnwn.mp4  \n",
            "  inflating: test_videos/aqrsylrzgi.mp4  \n",
            "  inflating: test_videos/axfhbpkdlc.mp4  \n",
            "  inflating: test_videos/ayipraspbn.mp4  \n",
            "  inflating: test_videos/bcbqxhziqz.mp4  \n",
            "  inflating: test_videos/bcvheslzrq.mp4  \n",
            "  inflating: test_videos/bdshuoldwx.mp4  \n",
            "  inflating: test_videos/bfdopzvxbi.mp4  \n",
            "  inflating: test_videos/bfjsthfhbd.mp4  \n",
            "  inflating: test_videos/bjyaxvggle.mp4  \n",
            "  inflating: test_videos/bkcyglmfci.mp4  \n",
            "  inflating: test_videos/bktkwbcawi.mp4  \n",
            "  inflating: test_videos/bkuzquigyt.mp4  \n",
            "  inflating: test_videos/blnmxntbey.mp4  \n",
            "  inflating: test_videos/blszgmxkvu.mp4  \n",
            "  inflating: test_videos/bnuwxhfahw.mp4  \n",
            "  inflating: test_videos/bofrwgeyjo.mp4  \n",
            "  inflating: test_videos/btdxnajogv.mp4  \n",
            "  inflating: test_videos/bvpeerislp.mp4  \n",
            "  inflating: test_videos/bwdmzwhdnw.mp4  \n",
            "  inflating: test_videos/bzvzpwrabw.mp4  \n",
            "  inflating: test_videos/cekarydqba.mp4  \n",
            "  inflating: test_videos/cekwtyxdoo.mp4  \n",
            "  inflating: test_videos/cjkctqqakb.mp4  \n",
            "  inflating: test_videos/cnpanmywno.mp4  \n",
            "  inflating: test_videos/cnxccbjlct.mp4  \n",
            "  inflating: test_videos/coqwgzpbhx.mp4  \n",
            "  inflating: test_videos/cosghhimnd.mp4  \n",
            "  inflating: test_videos/coujjnypba.mp4  \n",
            "  inflating: test_videos/cqhwesrciw.mp4  \n",
            "  inflating: test_videos/cqxxumarvp.mp4  \n",
            "  inflating: test_videos/csnkohqxdv.mp4  \n",
            "  inflating: test_videos/cxsvvnxpyz.mp4  \n",
            "  inflating: test_videos/czfqlbcfpa.mp4  \n",
            "  inflating: test_videos/dcqodpzomd.mp4  \n",
            "  inflating: test_videos/ddtbarpcgo.mp4  \n",
            "  inflating: test_videos/demuhxssgl.mp4  \n",
            "  inflating: test_videos/didzujjhtg.mp4  \n",
            "  inflating: test_videos/dkuqbduxev.mp4  \n",
            "  inflating: test_videos/dmmvuaikkv.mp4  \n",
            "  inflating: test_videos/dnmowthjcj.mp4  \n",
            "  inflating: test_videos/doniqevxeg.mp4  \n",
            "  inflating: test_videos/dozjwhnedd.mp4  \n",
            "  inflating: test_videos/dpevefkefv.mp4  \n",
            "  inflating: test_videos/dpmgoiwhuf.mp4  \n",
            "  inflating: test_videos/dsnxgrfdmd.mp4  \n",
            "  inflating: test_videos/dtozwcapoa.mp4  \n",
            "  inflating: test_videos/dvkdfhrpph.mp4  \n",
            "  inflating: test_videos/dvtpwatuja.mp4  \n",
            "  inflating: test_videos/dvwpvqdflx.mp4  \n",
            "  inflating: test_videos/dxfdovivlw.mp4  \n",
            "  inflating: test_videos/dxgnpnowgk.mp4  \n",
            "  inflating: test_videos/dyjklprkoc.mp4  \n",
            "  inflating: test_videos/dzkyxbbqkr.mp4  \n",
            "  inflating: test_videos/dzojiwfvba.mp4  \n",
            "  inflating: test_videos/ecumyiowzs.mp4  \n",
            "  inflating: test_videos/eisofhptvk.mp4  \n",
            "  inflating: test_videos/ekboxwrwuv.mp4  \n",
            "  inflating: test_videos/ekelfsnqof.mp4  \n",
            "  inflating: test_videos/ekvwecwltj.mp4  \n",
            "  inflating: test_videos/elackxuccp.mp4  \n",
            "  inflating: test_videos/eppyqpgewp.mp4  \n",
            "  inflating: test_videos/eqslzbqfea.mp4  \n",
            "  inflating: test_videos/eryjktdexi.mp4  \n",
            "  inflating: test_videos/esjdyghhog.mp4  \n",
            "  inflating: test_videos/esmqxszybs.mp4  \n",
            "  inflating: test_videos/espkiocpxq.mp4  \n",
            "  inflating: test_videos/etdliwticv.mp4  \n",
            "  inflating: test_videos/evysmtpnrf.mp4  \n",
            "  inflating: test_videos/eyguqfmgzh.mp4  \n",
            "  inflating: test_videos/eywdmustbb.mp4  \n",
            "  inflating: test_videos/famlupsgqm.mp4  \n",
            "  inflating: test_videos/fddmkqjwsh.mp4  \n",
            "  inflating: test_videos/fjrueenjyp.mp4  \n",
            "  inflating: test_videos/fjxovgmwnm.mp4  \n",
            "  inflating: test_videos/fmhiujydwo.mp4  \n",
            "  inflating: test_videos/fmvvmcbdrw.mp4  \n",
            "  inflating: test_videos/fneqiqpqvs.mp4  \n",
            "  inflating: test_videos/fnxgqcvlsd.mp4  \n",
            "  inflating: test_videos/fopjiyxiqd.mp4  \n",
            "  inflating: test_videos/fpevfidstw.mp4  \n",
            "  inflating: test_videos/fqgypsunzr.mp4  \n",
            "  inflating: test_videos/frqfsucgao.mp4  \n",
            "  inflating: test_videos/fsdrwikhge.mp4  \n",
            "  inflating: test_videos/fwykevubzy.mp4  \n",
            "  inflating: test_videos/fxuxxtryjn.mp4  \n",
            "  inflating: test_videos/fzvpbrzssi.mp4  \n",
            "  inflating: test_videos/gahgyuwzbu.mp4  \n",
            "  inflating: test_videos/gbnzicjyhz.mp4  \n",
            "  inflating: test_videos/gccnvdoknm.mp4  \n",
            "  inflating: test_videos/gcdtglsoqj.mp4  \n",
            "  inflating: test_videos/gfcycflhbo.mp4  \n",
            "  inflating: test_videos/gfdjzwnpyp.mp4  \n",
            "  inflating: test_videos/gfgcwxkbjd.mp4  \n",
            "  inflating: test_videos/ggdpclfcgk.mp4  \n",
            "  inflating: test_videos/ggzjfrirjh.mp4  \n",
            "  inflating: test_videos/ghnpsltzyn.mp4  \n",
            "  inflating: test_videos/gkutjglghz.mp4  \n",
            "  inflating: test_videos/gochxzemmq.mp4  \n",
            "  inflating: test_videos/gpsxfxrjrr.mp4  \n",
            "  inflating: test_videos/gqnaxievjx.mp4  \n",
            "  inflating: test_videos/gunamloolc.mp4  \n",
            "  inflating: test_videos/halvwiltfs.mp4  \n",
            "  inflating: test_videos/hbufmvbium.mp4  \n",
            "  inflating: test_videos/hcanfkwivl.mp4  \n",
            "  inflating: test_videos/hclsparpth.mp4  \n",
            "  inflating: test_videos/hefisnapds.mp4  \n",
            "  inflating: test_videos/heiyoojifp.mp4  \n",
            "  inflating: test_videos/hevcclcklc.mp4  \n",
            "  inflating: test_videos/hfsvqabzfq.mp4  \n",
            "  inflating: test_videos/hicjuubiau.mp4  \n",
            "  inflating: test_videos/hierggamuo.mp4  \n",
            "  inflating: test_videos/hitfycdavv.mp4  \n",
            "  inflating: test_videos/hnfwagcxdf.mp4  \n",
            "  inflating: test_videos/honxqdilvv.mp4  \n",
            "  inflating: test_videos/hqzwudvhih.mp4  \n",
            "  inflating: test_videos/hsbljbsgxr.mp4  \n",
            "  inflating: test_videos/hsbwhlolsn.mp4  \n",
            "  inflating: test_videos/hszwwswewp.mp4  \n",
            "  inflating: test_videos/htzbnroagi.mp4  \n",
            "  inflating: test_videos/huvlwkxoxm.mp4  \n",
            "  inflating: test_videos/hweshqpfwe.mp4  \n",
            "  inflating: test_videos/hxwtsaydal.mp4  \n",
            "  inflating: test_videos/hyjqolupxn.mp4  \n",
            "  inflating: test_videos/hzoiotcykp.mp4  \n",
            "  inflating: test_videos/hzssdinxec.mp4  \n",
            "  inflating: test_videos/ibxfxggtqh.mp4  \n",
            "  inflating: test_videos/icbsahlivv.mp4  \n",
            "  inflating: test_videos/igpvrfjdzc.mp4  \n",
            "  inflating: test_videos/ihglzxzroo.mp4  \n",
            "  inflating: test_videos/iksxzpqxzi.mp4  \n",
            "  inflating: test_videos/ilqwcbprqa.mp4  \n",
            "  inflating: test_videos/imdmhwkkni.mp4  \n",
            "  inflating: test_videos/iorbtaarte.mp4  \n",
            "  inflating: test_videos/ipkpxvwroe.mp4  \n",
            "  inflating: test_videos/ipvwtgdlre.mp4  \n",
            "  inflating: test_videos/irqzdokcws.mp4  \n",
            "  inflating: test_videos/itfsvvmslp.mp4  \n",
            "  inflating: test_videos/iznnzjvaxc.mp4  \n",
            "  inflating: test_videos/jawgcggquk.mp4  \n",
            "  inflating: test_videos/jhczqfefgw.mp4  \n",
            "  inflating: test_videos/jiavqbrkyk.mp4  \n",
            "  inflating: test_videos/jiswxuqzyz.mp4  \n",
            "  inflating: test_videos/jquevmhdvc.mp4  \n",
            "  inflating: test_videos/jsbpkpxwew.mp4  \n",
            "  inflating: test_videos/jsysgmycsx.mp4  \n",
            "  inflating: test_videos/jyfvaequfg.mp4  \n",
            "  inflating: test_videos/jyoxdvxpza.mp4  \n",
            "  inflating: test_videos/jytrvwlewz.mp4  \n",
            "  inflating: test_videos/jzmzdispyo.mp4  \n",
            "  inflating: test_videos/kcjvhgvhpt.mp4  \n",
            "  inflating: test_videos/keioymnobc.mp4  \n",
            "  inflating: test_videos/kezwvsxxzj.mp4  \n",
            "  inflating: test_videos/khpipxnsvx.mp4  \n",
            "  inflating: test_videos/kmcdjxmnoa.mp4  \n",
            "  inflating: test_videos/kmqkiihrmj.mp4  \n",
            "  inflating: test_videos/knxltsvzyu.mp4  \n",
            "  inflating: test_videos/kowiwvrjht.mp4  \n",
            "  inflating: test_videos/kqlvggiqee.mp4  \n",
            "  inflating: test_videos/kvmpmhdxly.mp4  \n",
            "  inflating: test_videos/kwfdyqofzw.mp4  \n",
            "  inflating: test_videos/lbfqksftuo.mp4  \n",
            "  inflating: test_videos/lbigytrrtr.mp4  \n",
            "  inflating: test_videos/lebzjtusnr.mp4  \n",
            "  inflating: test_videos/lhvjzhjxdp.mp4  \n",
            "  inflating: test_videos/ljauauuyka.mp4  \n",
            "  inflating: test_videos/ljouzjaqqe.mp4  \n",
            "  inflating: test_videos/llplvmcvbl.mp4  \n",
            "  inflating: test_videos/lmdyicksrv.mp4  \n",
            "  inflating: test_videos/lnhkjhyhvw.mp4  \n",
            "  inflating: test_videos/lnjkpdviqb.mp4  \n",
            "  inflating: test_videos/lpgxwdgnio.mp4  \n",
            "  inflating: test_videos/lpkgabskbw.mp4  \n",
            "  inflating: test_videos/lujvyveojc.mp4  \n",
            "  inflating: test_videos/lyoslorecs.mp4  \n",
            "  inflating: test_videos/mdfndlljvt.mp4  \n",
            "  inflating: test_videos/mkmgcxaztt.mp4  \n",
            "  inflating: test_videos/mkzaekkvej.mp4  \n",
            "  inflating: test_videos/mllzkpgatp.mp4  \n",
            "  inflating: test_videos/mnowxangqx.mp4  \n",
            "  inflating: test_videos/mnzabbkpmt.mp4  \n",
            "  inflating: test_videos/mohiqoogpb.mp4  \n",
            "  inflating: test_videos/mszblrdprw.mp4  \n",
            "  inflating: test_videos/mwnibuujwz.mp4  \n",
            "  inflating: test_videos/mwwploizlj.mp4  \n",
            "  inflating: test_videos/mxahsihabr.mp4  \n",
            "  inflating: test_videos/mxlipjhmqk.mp4  \n",
            "  inflating: test_videos/ncmpqwmnzb.mp4  \n",
            "  inflating: test_videos/ncoeewrdlo.mp4  \n",
            "  inflating: test_videos/ndikguxzek.mp4  \n",
            "  inflating: test_videos/nikynwcvuh.mp4  \n",
            "  inflating: test_videos/njzshtfmcw.mp4  \n",
            "  inflating: test_videos/nkhzxomani.mp4  \n",
            "  inflating: test_videos/novarhxpbj.mp4  \n",
            "  inflating: test_videos/nplviymzlg.mp4  \n",
            "  inflating: test_videos/nswtvttxre.mp4  \n",
            "  inflating: test_videos/nthpnwylxo.mp4  \n",
            "  inflating: test_videos/nwvloufjty.mp4  \n",
            "  inflating: test_videos/nwvsbmyndn.mp4  \n",
            "  inflating: test_videos/nxgzmgzkfv.mp4  \n",
            "  inflating: test_videos/nxnmkytwze.mp4  \n",
            "  inflating: test_videos/nxzgekegsp.mp4  \n",
            "  inflating: test_videos/nycmyuzpml.mp4  \n",
            "  inflating: test_videos/nymodlmxni.mp4  \n",
            "  inflating: test_videos/oaguiggjyv.mp4  \n",
            "  inflating: test_videos/ocgdbrgmtq.mp4  \n",
            "  inflating: test_videos/oefukgnvel.mp4  \n",
            "  inflating: test_videos/oelqpetgwj.mp4  \n",
            "  inflating: test_videos/ojsxxkalat.mp4  \n",
            "  inflating: test_videos/okgelildpc.mp4  \n",
            "  inflating: test_videos/omphqltjdd.mp4  \n",
            "  inflating: test_videos/ooafcxxfrs.mp4  \n",
            "  inflating: test_videos/oocincvedt.mp4  \n",
            "  inflating: test_videos/oojxonbgow.mp4  \n",
            "  inflating: test_videos/opvqdabdap.mp4  \n",
            "  inflating: test_videos/orekjthsef.mp4  \n",
            "  inflating: test_videos/orixbcfvdz.mp4  \n",
            "  inflating: test_videos/ouaowjmigq.mp4  \n",
            "  inflating: test_videos/owaogcehvc.mp4  \n",
            "  inflating: test_videos/oyqgwjdwaj.mp4  \n",
            "  inflating: test_videos/oysopgovhu.mp4  \n",
            "  inflating: test_videos/papagllumt.mp4  \n",
            "  inflating: test_videos/pcoxcmtroa.mp4  \n",
            "  inflating: test_videos/pcyswtgick.mp4  \n",
            "  inflating: test_videos/pdswwyyntw.mp4  \n",
            "  inflating: test_videos/pdufsewrec.mp4  \n",
            "  inflating: test_videos/petmyhjclt.mp4  \n",
            "  inflating: test_videos/phjvutxpoi.mp4  \n",
            "  inflating: test_videos/pqdeutauqc.mp4  \n",
            "  inflating: test_videos/pqthmvwonf.mp4  \n",
            "  inflating: test_videos/prhmixykhr.mp4  \n",
            "  inflating: test_videos/prwsfljdjo.mp4  \n",
            "  inflating: test_videos/psesikjaxx.mp4  \n",
            "  inflating: test_videos/ptbfnkajyi.mp4  \n",
            "  inflating: test_videos/ptbnewtvon.mp4  \n",
            "  inflating: test_videos/pxcfrszlgi.mp4  \n",
            "  inflating: test_videos/pxjkzvqomp.mp4  \n",
            "  inflating: test_videos/qarqtkvgby.mp4  \n",
            "  inflating: test_videos/qcbkztamqc.mp4  \n",
            "  inflating: test_videos/qclpbcbgeq.mp4  \n",
            "  inflating: test_videos/qdqdsaiitt.mp4  \n",
            "  inflating: test_videos/qhkzlnzruj.mp4  \n",
            "  inflating: test_videos/qhsehzgxqj.mp4  \n",
            "  inflating: test_videos/qlqhjcshpk.mp4  \n",
            "  inflating: test_videos/qlvsqdroqo.mp4  \n",
            "  inflating: test_videos/qooxnxqqjb.mp4  \n",
            "  inflating: test_videos/qqnlrngaft.mp4  \n",
            "  inflating: test_videos/qsjiypnjwi.mp4  \n",
            "  inflating: test_videos/qswlzfgcgj.mp4  \n",
            "  inflating: test_videos/qxyrtwozyw.mp4  \n",
            "  inflating: test_videos/qyyhuvqmyf.mp4  \n",
            "  inflating: test_videos/rcecrgeotc.mp4  \n",
            "  inflating: test_videos/rcjfxxhcal.mp4  \n",
            "  inflating: test_videos/rerpivllud.mp4  \n",
            "  inflating: test_videos/rfjuhbnlro.mp4  \n",
            "  inflating: test_videos/rfwxcinshk.mp4  \n",
            "  inflating: test_videos/rklawjhbpv.mp4  \n",
            "  inflating: test_videos/rktrpsdlci.mp4  \n",
            "  inflating: test_videos/rmlzgerevr.mp4  \n",
            "  inflating: test_videos/rmufsuogzn.mp4  \n",
            "  inflating: test_videos/rnfcjxynfa.mp4  \n",
            "  inflating: test_videos/rrrfjhugvb.mp4  \n",
            "  inflating: test_videos/rtpbawlmxr.mp4  \n",
            "  inflating: test_videos/ruhtnngrqv.mp4  \n",
            "  inflating: test_videos/rukyxomwcx.mp4  \n",
            "  inflating: test_videos/rvvpazsffd.mp4  \n",
            "  inflating: test_videos/rxdoimqble.mp4  \n",
            "  inflating: test_videos/ryxaqpfubf.mp4  \n",
            "  inflating: test_videos/scbdenmaed.mp4  \n",
            "  inflating: test_videos/scrbqgpvzz.mp4  \n",
            "  inflating: test_videos/sfsayjgzrh.mp4  \n",
            "  inflating: test_videos/shnsajrsow.mp4  \n",
            "  inflating: test_videos/siebfpwuhu.mp4  \n",
            "  inflating: test_videos/sjinmmbipg.mp4  \n",
            "  inflating: test_videos/sjkfxrlxxs.mp4  \n",
            "  inflating: test_videos/sjwywglgym.mp4  \n",
            "  inflating: test_videos/sktpeppbkc.mp4  \n",
            "  inflating: test_videos/sngjsueuhs.mp4  \n",
            "  inflating: test_videos/snlyjbnpgw.mp4  \n",
            "  inflating: test_videos/sodvtfqbpf.mp4  \n",
            "  inflating: test_videos/sqixhnilfm.mp4  \n",
            "  inflating: test_videos/srfefmyjvt.mp4  \n",
            "  inflating: test_videos/sufvvwmbha.mp4  \n",
            "  inflating: test_videos/swsaoktwgi.mp4  \n",
            "  inflating: test_videos/sylnrepacf.mp4  \n",
            "  inflating: test_videos/syuxttuyhm.mp4  \n",
            "  inflating: test_videos/syxobtuucp.mp4  \n",
            "  inflating: test_videos/sznkemeqro.mp4  \n",
            "  inflating: test_videos/tejfudfgpq.mp4  \n",
            "  inflating: test_videos/temeqbmzxu.mp4  \n",
            "  inflating: test_videos/temjefwaas.mp4  \n",
            "  inflating: test_videos/tgawasvbbr.mp4  \n",
            "  inflating: test_videos/tjuihawuqm.mp4  \n",
            "  inflating: test_videos/tjywwgftmv.mp4  \n",
            "  inflating: test_videos/toinozytsp.mp4  \n",
            "  inflating: test_videos/tvhjcfnqtg.mp4  \n",
            "  inflating: test_videos/txmnoyiyte.mp4  \n",
            "  inflating: test_videos/txnmkabufs.mp4  \n",
            "  inflating: test_videos/tyjpjpglgx.mp4  \n",
            "  inflating: test_videos/tynfsthodx.mp4  \n",
            "  inflating: test_videos/ucthmsajay.mp4  \n",
            "  inflating: test_videos/udxqbhgvvx.mp4  \n",
            "  inflating: test_videos/uhakqelqri.mp4  \n",
            "  inflating: test_videos/uhrqlmlclw.mp4  \n",
            "  inflating: test_videos/uoccaiathd.mp4  \n",
            "  inflating: test_videos/upmgtackuf.mp4  \n",
            "  inflating: test_videos/uqvxjfpwdo.mp4  \n",
            "  inflating: test_videos/usqqvxcjmg.mp4  \n",
            "  inflating: test_videos/uubgqnvfdl.mp4  \n",
            "  inflating: test_videos/uvrzaczrbx.mp4  \n",
            "  inflating: test_videos/uxuvkrjhws.mp4  \n",
            "  inflating: test_videos/vajkicalux.mp4  \n",
            "  inflating: test_videos/vbcgoyxsvn.mp4  \n",
            "  inflating: test_videos/vdtsbqidjb.mp4  \n",
            "  inflating: test_videos/vhbbwdflyh.mp4  \n",
            "  inflating: test_videos/viteugozpv.mp4  \n",
            "  inflating: test_videos/vizerpsvbz.mp4  \n",
            "  inflating: test_videos/vjljdfopjg.mp4  \n",
            "  inflating: test_videos/vmxfwxgdei.mp4  \n",
            "  inflating: test_videos/vnlzxqwthl.mp4  \n",
            "  inflating: test_videos/voawxrmqyl.mp4  \n",
            "  inflating: test_videos/vokrpfjpeb.mp4  \n",
            "  inflating: test_videos/vssmlqoiti.mp4  \n",
            "  inflating: test_videos/vtunvalyji.mp4  \n",
            "  inflating: test_videos/vurjckblge.mp4  \n",
            "  inflating: test_videos/vvfszaosiv.mp4  \n",
            "  inflating: test_videos/vwxednhlwz.mp4  \n",
            "  inflating: test_videos/wadvzjhwtw.mp4  \n",
            "  inflating: test_videos/waucvvmtkq.mp4  \n",
            "  inflating: test_videos/wclvkepakb.mp4  \n",
            "  inflating: test_videos/wcqvzujamg.mp4  \n",
            "  inflating: test_videos/wcssbghcpc.mp4  \n",
            "  inflating: test_videos/wcvsqnplsk.mp4  \n",
            "  inflating: test_videos/wfzjxzhdkj.mp4  \n",
            "  inflating: test_videos/wixbuuzygv.mp4  \n",
            "  inflating: test_videos/wjhpisoeaj.mp4  \n",
            "  inflating: test_videos/wmoqzxddkb.mp4  \n",
            "  inflating: test_videos/wndursivcx.mp4  \n",
            "  inflating: test_videos/wnlubukrki.mp4  \n",
            "  inflating: test_videos/wqysrieiqu.mp4  \n",
            "  inflating: test_videos/wvgviwnwob.mp4  \n",
            "  inflating: test_videos/wynotylpnm.mp4  \n",
            "  inflating: test_videos/xcruhaccxc.mp4  \n",
            "  inflating: test_videos/xdezcezszc.mp4  \n",
            "  inflating: test_videos/xhtppuyqdr.mp4  \n",
            "  inflating: test_videos/xitgdpzbxv.mp4  \n",
            "  inflating: test_videos/xjvxtuakyd.mp4  \n",
            "  inflating: test_videos/xljemofssi.mp4  \n",
            "  inflating: test_videos/xmkwsnuzyq.mp4  \n",
            "  inflating: test_videos/xphdfgmfmz.mp4  \n",
            "  inflating: test_videos/xrtvqhdibb.mp4  \n",
            "  inflating: test_videos/xugmhbetrw.mp4  \n",
            "  inflating: test_videos/xxzefxwyku.mp4  \n",
            "  inflating: test_videos/yarpxfqejd.mp4  \n",
            "  inflating: test_videos/yaxgpxhavq.mp4  \n",
            "  inflating: test_videos/ybbrkacebd.mp4  \n",
            "  inflating: test_videos/yhjlnisfel.mp4  \n",
            "  inflating: test_videos/yhylappzid.mp4  \n",
            "  inflating: test_videos/yietrwuncf.mp4  \n",
            "  inflating: test_videos/yiykshcbaz.mp4  \n",
            "  inflating: test_videos/yljecirelf.mp4  \n",
            "  inflating: test_videos/yllztsrwjw.mp4  \n",
            "  inflating: test_videos/ylxwcwhjjd.mp4  \n",
            "  inflating: test_videos/yoyhmxtrys.mp4  \n",
            "  inflating: test_videos/ypbtpunjvm.mp4  \n",
            "  inflating: test_videos/yqhouqakbx.mp4  \n",
            "  inflating: test_videos/yronlutbgm.mp4  \n",
            "  inflating: test_videos/ystdtnetgj.mp4  \n",
            "  inflating: test_videos/ytddugrwph.mp4  \n",
            "  inflating: test_videos/ytopzxrswu.mp4  \n",
            "  inflating: test_videos/ywauoonmlr.mp4  \n",
            "  inflating: test_videos/ywxpquomgt.mp4  \n",
            "  inflating: test_videos/yxadevzohx.mp4  \n",
            "  inflating: test_videos/yxirnfyijn.mp4  \n",
            "  inflating: test_videos/yxvmusxvcz.mp4  \n",
            "  inflating: test_videos/yzuestxcbq.mp4  \n",
            "  inflating: test_videos/zbgssotnjm.mp4  \n",
            "  inflating: test_videos/zcxcmneefk.mp4  \n",
            "  inflating: test_videos/zfobicuigx.mp4  \n",
            "  inflating: test_videos/zfrrixsimm.mp4  \n",
            "  inflating: test_videos/zgbhzkditd.mp4  \n",
            "  inflating: test_videos/zgjosltkie.mp4  \n",
            "  inflating: test_videos/ziipxxchai.mp4  \n",
            "  inflating: test_videos/zmxeiipnqb.mp4  \n",
            "  inflating: test_videos/ztyuiqrhdk.mp4  \n",
            "  inflating: test_videos/ztyvglkcsf.mp4  \n",
            "  inflating: test_videos/zuwwbbusgl.mp4  \n",
            "  inflating: test_videos/zxacihctqp.mp4  \n",
            "  inflating: test_videos/zyufpqvpyu.mp4  \n",
            "  inflating: test_videos/zzmgnglanj.mp4  \n",
            "  inflating: train_sample_videos/aagfhgtpmv.mp4  \n",
            "  inflating: train_sample_videos/aapnvogymq.mp4  \n",
            "  inflating: train_sample_videos/abarnvbtwb.mp4  \n",
            "  inflating: train_sample_videos/abofeumbvv.mp4  \n",
            "  inflating: train_sample_videos/abqwwspghj.mp4  \n",
            "  inflating: train_sample_videos/acifjvzvpm.mp4  \n",
            "  inflating: train_sample_videos/acqfdwsrhi.mp4  \n",
            "  inflating: train_sample_videos/acxnxvbsxk.mp4  \n",
            "  inflating: train_sample_videos/acxwigylke.mp4  \n",
            "  inflating: train_sample_videos/aczrgyricp.mp4  \n",
            "  inflating: train_sample_videos/adhsbajydo.mp4  \n",
            "  inflating: train_sample_videos/adohikbdaz.mp4  \n",
            "  inflating: train_sample_videos/adylbeequz.mp4  \n",
            "  inflating: train_sample_videos/aelfnikyqj.mp4  \n",
            "  inflating: train_sample_videos/aelzhcnwgf.mp4  \n",
            "  inflating: train_sample_videos/aettqgevhz.mp4  \n",
            "  inflating: train_sample_videos/aevrfsexku.mp4  \n",
            "  inflating: train_sample_videos/afoovlsmtx.mp4  \n",
            "  inflating: train_sample_videos/agdkmztvby.mp4  \n",
            "  inflating: train_sample_videos/agqphdxmwt.mp4  \n",
            "  inflating: train_sample_videos/agrmhtjdlk.mp4  \n",
            "  inflating: train_sample_videos/ahbweevwpv.mp4  \n",
            "  inflating: train_sample_videos/ahdbuwqxit.mp4  \n",
            "  inflating: train_sample_videos/ahfazfbntc.mp4  \n",
            "  inflating: train_sample_videos/ahqqqilsxt.mp4  \n",
            "  inflating: train_sample_videos/aipfdnwpoo.mp4  \n",
            "  inflating: train_sample_videos/ajqslcypsw.mp4  \n",
            "  inflating: train_sample_videos/ajwpjhrbcv.mp4  \n",
            "  inflating: train_sample_videos/aklqzsddfl.mp4  \n",
            "  inflating: train_sample_videos/aknbdpmgua.mp4  \n",
            "  inflating: train_sample_videos/aknmpoonls.mp4  \n",
            "  inflating: train_sample_videos/akvmwkdyuv.mp4  \n",
            "  inflating: train_sample_videos/akxoopqjqz.mp4  \n",
            "  inflating: train_sample_videos/akzbnazxtz.mp4  \n",
            "  inflating: train_sample_videos/aladcziidp.mp4  \n",
            "  inflating: train_sample_videos/alaijyygdv.mp4  \n",
            "  inflating: train_sample_videos/alninxcyhg.mp4  \n",
            "  inflating: train_sample_videos/altziddtxi.mp4  \n",
            "  inflating: train_sample_videos/alvgwypubw.mp4  \n",
            "  inflating: train_sample_videos/amaivqofda.mp4  \n",
            "  inflating: train_sample_videos/amowujxmzc.mp4  \n",
            "  inflating: train_sample_videos/andaxzscny.mp4  \n",
            "  inflating: train_sample_videos/aneclqfpbt.mp4  \n",
            "  inflating: train_sample_videos/anpuvshzoo.mp4  \n",
            "  inflating: train_sample_videos/aorjvbyxhw.mp4  \n",
            "  inflating: train_sample_videos/apatcsqejh.mp4  \n",
            "  inflating: train_sample_videos/apgjqzkoma.mp4  \n",
            "  inflating: train_sample_videos/apogckdfrz.mp4  \n",
            "  inflating: train_sample_videos/aqpnvjhuzw.mp4  \n",
            "  inflating: train_sample_videos/arkroixhey.mp4  \n",
            "  inflating: train_sample_videos/arlmiizoob.mp4  \n",
            "  inflating: train_sample_videos/arrhsnjqku.mp4  \n",
            "  inflating: train_sample_videos/asaxgevnnp.mp4  \n",
            "  inflating: train_sample_videos/asdpeebotb.mp4  \n",
            "  inflating: train_sample_videos/aslsvlvpth.mp4  \n",
            "  inflating: train_sample_videos/asmpfjfzif.mp4  \n",
            "  inflating: train_sample_videos/asvcrfdpnq.mp4  \n",
            "  inflating: train_sample_videos/atkdltyyen.mp4  \n",
            "  inflating: train_sample_videos/atvmxvwyns.mp4  \n",
            "  inflating: train_sample_videos/atxvxouljq.mp4  \n",
            "  inflating: train_sample_videos/atyntldecu.mp4  \n",
            "  inflating: train_sample_videos/atzdznmder.mp4  \n",
            "  inflating: train_sample_videos/aufmsmnoye.mp4  \n",
            "  inflating: train_sample_videos/augtsuxpzc.mp4  \n",
            "  inflating: train_sample_videos/avfitoutyn.mp4  \n",
            "  inflating: train_sample_videos/avgiuextiz.mp4  \n",
            "  inflating: train_sample_videos/avibnnhwhp.mp4  \n",
            "  inflating: train_sample_videos/avmjormvsx.mp4  \n",
            "  inflating: train_sample_videos/avnqydkqjj.mp4  \n",
            "  inflating: train_sample_videos/avssvvsdhz.mp4  \n",
            "  inflating: train_sample_videos/avtycwsgyb.mp4  \n",
            "  inflating: train_sample_videos/avvdgsennp.mp4  \n",
            "  inflating: train_sample_videos/avywawptfc.mp4  \n",
            "  inflating: train_sample_videos/awhmfnnjih.mp4  \n",
            "  inflating: train_sample_videos/awnwkrqibf.mp4  \n",
            "  inflating: train_sample_videos/awukslzjra.mp4  \n",
            "  inflating: train_sample_videos/axczxisdtb.mp4  \n",
            "  inflating: train_sample_videos/axntxmycwd.mp4  \n",
            "  inflating: train_sample_videos/axoygtekut.mp4  \n",
            "  inflating: train_sample_videos/axwgcsyphv.mp4  \n",
            "  inflating: train_sample_videos/axwovszumc.mp4  \n",
            "  inflating: train_sample_videos/aybgughjxh.mp4  \n",
            "  inflating: train_sample_videos/aybumesmpk.mp4  \n",
            "  inflating: train_sample_videos/ayqvfdhslr.mp4  \n",
            "  inflating: train_sample_videos/aytzyidmgs.mp4  \n",
            "  inflating: train_sample_videos/azpuxunqyo.mp4  \n",
            "  inflating: train_sample_videos/azsmewqghg.mp4  \n",
            "  inflating: train_sample_videos/bahdpoesir.mp4  \n",
            "  inflating: train_sample_videos/bbhpvrmbse.mp4  \n",
            "  inflating: train_sample_videos/bbhtdfuqxq.mp4  \n",
            "  inflating: train_sample_videos/bbvgxeczei.mp4  \n",
            "  inflating: train_sample_videos/bchnbulevv.mp4  \n",
            "  inflating: train_sample_videos/bctvsmddgq.mp4  \n",
            "  inflating: train_sample_videos/bdbhekrrwo.mp4  \n",
            "  inflating: train_sample_videos/bddjdhzfze.mp4  \n",
            "  inflating: train_sample_videos/bdgipnyobr.mp4  \n",
            "  inflating: train_sample_videos/bdnaqemxmr.mp4  \n",
            "  inflating: train_sample_videos/bdxuhamuqx.mp4  \n",
            "  inflating: train_sample_videos/beboztfcme.mp4  \n",
            "  inflating: train_sample_videos/bejhvclboh.mp4  \n",
            "  inflating: train_sample_videos/benmsfzfaz.mp4  \n",
            "  inflating: train_sample_videos/beyebyhrph.mp4  \n",
            "  inflating: train_sample_videos/bffwsjxghk.mp4  \n",
            "  inflating: train_sample_videos/bgaogsjehq.mp4  \n",
            "  inflating: train_sample_videos/bggsurpgpr.mp4  \n",
            "  inflating: train_sample_videos/bghphrsfxf.mp4  \n",
            "  inflating: train_sample_videos/bgmlwsoamc.mp4  \n",
            "  inflating: train_sample_videos/bguwlyazau.mp4  \n",
            "  inflating: train_sample_videos/bgvhtpzknn.mp4  \n",
            "  inflating: train_sample_videos/bgwmmujlmc.mp4  \n",
            "  inflating: train_sample_videos/bhaaboftbc.mp4  \n",
            "  inflating: train_sample_videos/bhbdugnurr.mp4  \n",
            "  inflating: train_sample_videos/bhpwpydzpo.mp4  \n",
            "  inflating: train_sample_videos/bhsluedavd.mp4  \n",
            "  inflating: train_sample_videos/bilnggbxgu.mp4  \n",
            "  inflating: train_sample_videos/bjjbwsqjir.mp4  \n",
            "  inflating: train_sample_videos/bjkmjilrxp.mp4  \n",
            "  inflating: train_sample_videos/bjsmaqefoi.mp4  \n",
            "  inflating: train_sample_videos/bkmdzhfzfh.mp4  \n",
            "  inflating: train_sample_videos/bkvetcojbt.mp4  \n",
            "  inflating: train_sample_videos/bkwxhglwct.mp4  \n",
            "  inflating: train_sample_videos/blpchvmhxx.mp4  \n",
            "  inflating: train_sample_videos/blzydqdfem.mp4  \n",
            "  inflating: train_sample_videos/bmbbkwmxqj.mp4  \n",
            "  inflating: train_sample_videos/bmehkyanbj.mp4  \n",
            "  inflating: train_sample_videos/bmhvktyiwp.mp4  \n",
            "  inflating: train_sample_videos/bmioepcpsx.mp4  \n",
            "  inflating: train_sample_videos/bmjmjmbglm.mp4  \n",
            "  inflating: train_sample_videos/bmjzrlszhi.mp4  \n",
            "  inflating: train_sample_videos/bnbuonyoje.mp4  \n",
            "  inflating: train_sample_videos/bndybcqhfr.mp4  \n",
            "  inflating: train_sample_videos/bnjcdrfuov.mp4  \n",
            "  inflating: train_sample_videos/bntlodcfeg.mp4  \n",
            "  inflating: train_sample_videos/bofqajtwve.mp4  \n",
            "  inflating: train_sample_videos/boovltmuwi.mp4  \n",
            "  inflating: train_sample_videos/bopqhhalml.mp4  \n",
            "  inflating: train_sample_videos/bourlmzsio.mp4  \n",
            "  inflating: train_sample_videos/bpapbctoao.mp4  \n",
            "  inflating: train_sample_videos/bpwzipqtxf.mp4  \n",
            "  inflating: train_sample_videos/bpxckdzddv.mp4  \n",
            "  inflating: train_sample_videos/bqdjzqhcft.mp4  \n",
            "  inflating: train_sample_videos/bqeiblbxtl.mp4  \n",
            "  inflating: train_sample_videos/bqhtpqmmqp.mp4  \n",
            "  inflating: train_sample_videos/bqkdbcqjvb.mp4  \n",
            "  inflating: train_sample_videos/bqnymlsayl.mp4  \n",
            "  inflating: train_sample_videos/bqqpbzjgup.mp4  \n",
            "  inflating: train_sample_videos/bqtuuwzdtr.mp4  \n",
            "  inflating: train_sample_videos/brhalypwoo.mp4  \n",
            "  inflating: train_sample_videos/brvqtabyxj.mp4  \n",
            "  inflating: train_sample_videos/brwrlczjvi.mp4  \n",
            "  inflating: train_sample_videos/bseamdrpbj.mp4  \n",
            "  inflating: train_sample_videos/bsfmwclnqy.mp4  \n",
            "  inflating: train_sample_videos/bsqgziaylx.mp4  \n",
            "  inflating: train_sample_videos/btiysiskpf.mp4  \n",
            "  inflating: train_sample_videos/btjlfpzbdu.mp4  \n",
            "  inflating: train_sample_videos/btjwbtsgln.mp4  \n",
            "  inflating: train_sample_videos/btmsngnqhv.mp4  \n",
            "  inflating: train_sample_videos/btohlidmru.mp4  \n",
            "  inflating: train_sample_videos/btugrnoton.mp4  \n",
            "  inflating: train_sample_videos/btunxncpjh.mp4  \n",
            "  inflating: train_sample_videos/btxlttbpkj.mp4  \n",
            "  inflating: train_sample_videos/bulkxhhknf.mp4  \n",
            "  inflating: train_sample_videos/bvgwelbeof.mp4  \n",
            "  inflating: train_sample_videos/bvzjkezkms.mp4  \n",
            "  inflating: train_sample_videos/bweezhfpzp.mp4  \n",
            "  inflating: train_sample_videos/bwhlgysghg.mp4  \n",
            "  inflating: train_sample_videos/bwipwzzxxu.mp4  \n",
            "  inflating: train_sample_videos/bwuwstvsbw.mp4  \n",
            "  inflating: train_sample_videos/bxzakyopjf.mp4  \n",
            "  inflating: train_sample_videos/bydaidkpdp.mp4  \n",
            "  inflating: train_sample_videos/byfenovjnf.mp4  \n",
            "  inflating: train_sample_videos/byijojkdba.mp4  \n",
            "  inflating: train_sample_videos/byofowlkki.mp4  \n",
            "  inflating: train_sample_videos/byqzyxifza.mp4  \n",
            "  inflating: train_sample_videos/byunigvnay.mp4  \n",
            "  inflating: train_sample_videos/byyqectxqa.mp4  \n",
            "  inflating: train_sample_videos/bzmdrafeex.mp4  \n",
            "  inflating: train_sample_videos/bzythlfnhq.mp4  \n",
            "  inflating: train_sample_videos/caifxvsozs.mp4  \n",
            "  inflating: train_sample_videos/caqbrkogkb.mp4  \n",
            "  inflating: train_sample_videos/cbbibzcoih.mp4  \n",
            "  inflating: train_sample_videos/cbltdtxglo.mp4  \n",
            "  inflating: train_sample_videos/ccfoszqabv.mp4  \n",
            "  inflating: train_sample_videos/ccmonzqfrz.mp4  \n",
            "  inflating: train_sample_videos/cdaxixbosp.mp4  \n",
            "  inflating: train_sample_videos/cdbsbdymzd.mp4  \n",
            "  inflating: train_sample_videos/cdphtzqrvp.mp4  \n",
            "  inflating: train_sample_videos/cdyakrxkia.mp4  \n",
            "  inflating: train_sample_videos/cepxysienc.mp4  \n",
            "  inflating: train_sample_videos/cettndmvzl.mp4  \n",
            "  inflating: train_sample_videos/ceymbecxnj.mp4  \n",
            "  inflating: train_sample_videos/cferslmfwh.mp4  \n",
            "  inflating: train_sample_videos/cffffbcywc.mp4  \n",
            "  inflating: train_sample_videos/cfxkpiweqt.mp4  \n",
            "  inflating: train_sample_videos/cfyduhpbps.mp4  \n",
            "  inflating: train_sample_videos/cglxirfaey.mp4  \n",
            "  inflating: train_sample_videos/cgvrgibpfo.mp4  \n",
            "  inflating: train_sample_videos/chtapglbcj.mp4  \n",
            "  inflating: train_sample_videos/chviwxsfhg.mp4  \n",
            "  inflating: train_sample_videos/chzieimrwu.mp4  \n",
            "  inflating: train_sample_videos/ciyoudyhly.mp4  \n",
            "  inflating: train_sample_videos/cizlkenljw.mp4  \n",
            "  inflating: train_sample_videos/ckbdwedgmc.mp4  \n",
            "  inflating: train_sample_videos/ckjaibzfxa.mp4  \n",
            "  inflating: train_sample_videos/ckkuyewywx.mp4  \n",
            "  inflating: train_sample_videos/cknyxaqouy.mp4  \n",
            "  inflating: train_sample_videos/cksanfsjhc.mp4  \n",
            "  inflating: train_sample_videos/clihsshdkq.mp4  \n",
            "  inflating: train_sample_videos/clrycekyst.mp4  \n",
            "  inflating: train_sample_videos/cmbzllswnl.mp4  \n",
            "  inflating: train_sample_videos/cmxcfkrjiv.mp4  \n",
            "  inflating: train_sample_videos/cnilkgvfei.mp4  \n",
            "  inflating: train_sample_videos/coadfnerlk.mp4  \n",
            "  inflating: train_sample_videos/cobjrlugvp.mp4  \n",
            "  inflating: train_sample_videos/covdcysmbi.mp4  \n",
            "  inflating: train_sample_videos/cpjxareypw.mp4  \n",
            "  inflating: train_sample_videos/cppdvdejkc.mp4  \n",
            "  inflating: train_sample_videos/cprhtltsjp.mp4  \n",
            "  inflating: train_sample_videos/cqfugiqupm.mp4  \n",
            "  inflating: train_sample_videos/cqhngvpgyi.mp4  \n",
            "  inflating: train_sample_videos/cqrskwiqng.mp4  \n",
            "  inflating: train_sample_videos/crezycjqyk.mp4  \n",
            "  inflating: train_sample_videos/crktehraph.mp4  \n",
            "  inflating: train_sample_videos/crzfebnfgb.mp4  \n",
            "  inflating: train_sample_videos/cthdnahrkh.mp4  \n",
            "  inflating: train_sample_videos/ctpqeykqdp.mp4  \n",
            "  inflating: train_sample_videos/cttqtsjvgn.mp4  \n",
            "  inflating: train_sample_videos/ctzmavwror.mp4  \n",
            "  inflating: train_sample_videos/curpwogllm.mp4  \n",
            "  inflating: train_sample_videos/cuzrgrbvil.mp4  \n",
            "  inflating: train_sample_videos/cvaksbpssm.mp4  \n",
            "  inflating: train_sample_videos/cwbacdwrzo.mp4  \n",
            "  inflating: train_sample_videos/cwqlvzefpg.mp4  \n",
            "  inflating: train_sample_videos/cwrtyzndpx.mp4  \n",
            "  inflating: train_sample_videos/cwsbspfzck.mp4  \n",
            "  inflating: train_sample_videos/cwwandrkus.mp4  \n",
            "  inflating: train_sample_videos/cxfujlvsuw.mp4  \n",
            "  inflating: train_sample_videos/cxrfacemmq.mp4  \n",
            "  inflating: train_sample_videos/cxttmymlbn.mp4  \n",
            "  inflating: train_sample_videos/cyboodqqyr.mp4  \n",
            "  inflating: train_sample_videos/cycacemkmt.mp4  \n",
            "  inflating: train_sample_videos/cyclgfjdrv.mp4  \n",
            "  inflating: train_sample_videos/cyxlcuyznd.mp4  \n",
            "  inflating: train_sample_videos/czfunozvwp.mp4  \n",
            "  inflating: train_sample_videos/czkdanyadc.mp4  \n",
            "  inflating: train_sample_videos/czmqpxrqoh.mp4  \n",
            "  inflating: train_sample_videos/dafhtipaml.mp4  \n",
            "  inflating: train_sample_videos/dakiztgtnw.mp4  \n",
            "  inflating: train_sample_videos/dakqwktlbi.mp4  \n",
            "  inflating: train_sample_videos/dbhoxkblzx.mp4  \n",
            "  inflating: train_sample_videos/dbhrpizyeq.mp4  \n",
            "  inflating: train_sample_videos/dbnygxtwek.mp4  \n",
            "  inflating: train_sample_videos/dboxtiehng.mp4  \n",
            "  inflating: train_sample_videos/dbtbbhakdv.mp4  \n",
            "  inflating: train_sample_videos/dbzcqmxzaj.mp4  \n",
            "  inflating: train_sample_videos/dbzpcjntve.mp4  \n",
            "  inflating: train_sample_videos/dcamvmuors.mp4  \n",
            "  inflating: train_sample_videos/dcuiiorugd.mp4  \n",
            "  inflating: train_sample_videos/ddepeddixj.mp4  \n",
            "  inflating: train_sample_videos/ddhfabwpuz.mp4  \n",
            "  inflating: train_sample_videos/ddjggcasdw.mp4  \n",
            "  inflating: train_sample_videos/ddpvuimigj.mp4  \n",
            "  inflating: train_sample_videos/ddqccgmtka.mp4  \n",
            "  inflating: train_sample_videos/degpbqvcay.mp4  \n",
            "  inflating: train_sample_videos/deywhkarol.mp4  \n",
            "  inflating: train_sample_videos/deyyistcrd.mp4  \n",
            "  inflating: train_sample_videos/dfbpceeaox.mp4  \n",
            "  inflating: train_sample_videos/dgmevclvzy.mp4  \n",
            "  inflating: train_sample_videos/dgxrqjdomn.mp4  \n",
            "  inflating: train_sample_videos/dgzklxjmix.mp4  \n",
            "  inflating: train_sample_videos/dhcndnuwta.mp4  \n",
            "  inflating: train_sample_videos/dhcselezer.mp4  \n",
            "  inflating: train_sample_videos/dhevettufk.mp4  \n",
            "  inflating: train_sample_videos/dhjmzhrcav.mp4  \n",
            "  inflating: train_sample_videos/dhkwmjxwrn.mp4  \n",
            "  inflating: train_sample_videos/dhoqofwoxa.mp4  \n",
            "  inflating: train_sample_videos/dhxctgyoqj.mp4  \n",
            "  inflating: train_sample_videos/diomeixhrg.mp4  \n",
            "  inflating: train_sample_videos/diopzaywor.mp4  \n",
            "  inflating: train_sample_videos/diqraixiov.mp4  \n",
            "  inflating: train_sample_videos/diuzrpqjli.mp4  \n",
            "  inflating: train_sample_videos/djvtbgwdcc.mp4  \n",
            "  inflating: train_sample_videos/djvutyvaio.mp4  \n",
            "  inflating: train_sample_videos/djxdyjopjd.mp4  \n",
            "  inflating: train_sample_videos/dkdwxmtpuo.mp4  \n",
            "  inflating: train_sample_videos/dkhlttuvmx.mp4  \n",
            "  inflating: train_sample_videos/dkrvorliqc.mp4  \n",
            "  inflating: train_sample_videos/dkuayagnmc.mp4  \n",
            "  inflating: train_sample_videos/dkwjwbwgey.mp4  \n",
            "  inflating: train_sample_videos/dkzvdrzcnr.mp4  \n",
            "  inflating: train_sample_videos/dlpoieqvfb.mp4  \n",
            "  inflating: train_sample_videos/dlrsbscitn.mp4  \n",
            "  inflating: train_sample_videos/dnexlwbcxq.mp4  \n",
            "  inflating: train_sample_videos/dnhvalzvrt.mp4  \n",
            "  inflating: train_sample_videos/dntkzzzcdh.mp4  \n",
            "  inflating: train_sample_videos/dnyvfblxpm.mp4  \n",
            "  inflating: train_sample_videos/doanjploai.mp4  \n",
            "  inflating: train_sample_videos/dofusvhnib.mp4  \n",
            "  inflating: train_sample_videos/dozyddhild.mp4  \n",
            "  inflating: train_sample_videos/dptbnjnkdg.mp4  \n",
            "  inflating: train_sample_videos/dptrzdvwpg.mp4  \n",
            "  inflating: train_sample_videos/dqnyszdong.mp4  \n",
            "  inflating: train_sample_videos/dqppxmoqdl.mp4  \n",
            "  inflating: train_sample_videos/dqqtjcryjv.mp4  \n",
            "  inflating: train_sample_videos/dqswpjoepo.mp4  \n",
            "  inflating: train_sample_videos/dqzreruvje.mp4  \n",
            "  inflating: train_sample_videos/drcyabprvt.mp4  \n",
            "  inflating: train_sample_videos/drgjzlxzxj.mp4  \n",
            "  inflating: train_sample_videos/drsakwyvqv.mp4  \n",
            "  inflating: train_sample_videos/drtbksnpol.mp4  \n",
            "  inflating: train_sample_videos/dsdoseflas.mp4  \n",
            "  inflating: train_sample_videos/dsgpbgsrdm.mp4  \n",
            "  inflating: train_sample_videos/dsjbknkujw.mp4  \n",
            "  inflating: train_sample_videos/dsndhujjjb.mp4  \n",
            "  inflating: train_sample_videos/dtbpmdqvao.mp4  \n",
            "  inflating: train_sample_videos/dtocdfbwca.mp4  \n",
            "  inflating: train_sample_videos/dubiroskqn.mp4  \n",
            "  inflating: train_sample_videos/dulanfulol.mp4  \n",
            "  inflating: train_sample_videos/duvyaxbzvp.mp4  \n",
            "  inflating: train_sample_videos/duycddgtrl.mp4  \n",
            "  inflating: train_sample_videos/duzuusuajr.mp4  \n",
            "  inflating: train_sample_videos/dvakowbgbt.mp4  \n",
            "  inflating: train_sample_videos/dvumqqhoac.mp4  \n",
            "  inflating: train_sample_videos/dwediigjit.mp4  \n",
            "  inflating: train_sample_videos/dxbqjxrhin.mp4  \n",
            "  inflating: train_sample_videos/dxuliowugt.mp4  \n",
            "  inflating: train_sample_videos/dxuplhwvig.mp4  \n",
            "  inflating: train_sample_videos/dzieklokdr.mp4  \n",
            "  inflating: train_sample_videos/dzqwgqewhu.mp4  \n",
            "  inflating: train_sample_videos/dzvyfiarrq.mp4  \n",
            "  inflating: train_sample_videos/dzwkmcwkwl.mp4  \n",
            "  inflating: train_sample_videos/dzyuwjkjui.mp4  \n",
            "  inflating: train_sample_videos/eahlqmfvtj.mp4  \n",
            "  inflating: train_sample_videos/eajlrktemq.mp4  \n",
            "  inflating: train_sample_videos/ebchwmwayp.mp4  \n",
            "  inflating: train_sample_videos/ebebgmtlcu.mp4  \n",
            "  inflating: train_sample_videos/ebeknhudxq.mp4  \n",
            "  inflating: train_sample_videos/ebkzwjgjhq.mp4  \n",
            "  inflating: train_sample_videos/ebywfrmhtd.mp4  \n",
            "  inflating: train_sample_videos/eckvhdusax.mp4  \n",
            "  inflating: train_sample_videos/ecnihjlfyt.mp4  \n",
            "  inflating: train_sample_videos/ecujsjhscd.mp4  \n",
            "  inflating: train_sample_videos/ecuvtoltue.mp4  \n",
            "  inflating: train_sample_videos/ecwaxgutkc.mp4  \n",
            "  inflating: train_sample_videos/eczrseixwq.mp4  \n",
            "  inflating: train_sample_videos/edyncaijwx.mp4  \n",
            "  inflating: train_sample_videos/eebrkicpry.mp4  \n",
            "  inflating: train_sample_videos/eebserckhh.mp4  \n",
            "  inflating: train_sample_videos/eejswgycjc.mp4  \n",
            "  inflating: train_sample_videos/eekozbeafq.mp4  \n",
            "  inflating: train_sample_videos/eepezmygaq.mp4  \n",
            "  inflating: train_sample_videos/eeyhxisdfh.mp4  \n",
            "  inflating: train_sample_videos/efdyrflcpg.mp4  \n",
            "  inflating: train_sample_videos/efwfxwwlbw.mp4  \n",
            "  inflating: train_sample_videos/egbbcxcuqy.mp4  \n",
            "  inflating: train_sample_videos/eggbjzxnmg.mp4  \n",
            "  inflating: train_sample_videos/egghxjjmfg.mp4  \n",
            "  inflating: train_sample_videos/ehbnclaukr.mp4  \n",
            "  inflating: train_sample_videos/ehccixxzoe.mp4  \n",
            "  inflating: train_sample_videos/ehdkmxgtxh.mp4  \n",
            "  inflating: train_sample_videos/ehevsxtecd.mp4  \n",
            "  inflating: train_sample_videos/ehfiekigla.mp4  \n",
            "  inflating: train_sample_videos/ehieahnhte.mp4  \n",
            "  inflating: train_sample_videos/ehtdtkmmli.mp4  \n",
            "  inflating: train_sample_videos/eiriyukqqy.mp4  \n",
            "  inflating: train_sample_videos/eivxffliio.mp4  \n",
            "  inflating: train_sample_videos/eiwopxzjfn.mp4  \n",
            "  inflating: train_sample_videos/eixwxvxbbn.mp4  \n",
            "  inflating: train_sample_videos/ejkqesyvam.mp4  \n",
            "  inflating: train_sample_videos/ekcrtigpab.mp4  \n",
            "  inflating: train_sample_videos/ekhacizpah.mp4  \n",
            "  inflating: train_sample_videos/ekkdjkirzq.mp4  \n",
            "  inflating: train_sample_videos/elginszwtk.mp4  \n",
            "  inflating: train_sample_videos/ellavthztb.mp4  \n",
            "  inflating: train_sample_videos/elvvackpjh.mp4  \n",
            "  inflating: train_sample_videos/emaalmsonj.mp4  \n",
            "  inflating: train_sample_videos/emfbhytfhc.mp4  \n",
            "  inflating: train_sample_videos/emgjphonqb.mp4  \n",
            "  inflating: train_sample_videos/ensyyivobf.mp4  \n",
            "  inflating: train_sample_videos/eoewqcpbgt.mp4  \n",
            "  inflating: train_sample_videos/eprybmbpba.mp4  \n",
            "  inflating: train_sample_videos/epymyyiblu.mp4  \n",
            "  inflating: train_sample_videos/eqjscdagiv.mp4  \n",
            "  inflating: train_sample_videos/eqnoqyfquo.mp4  \n",
            "  inflating: train_sample_videos/eqvuznuwsa.mp4  \n",
            "  inflating: train_sample_videos/erlvuvjsjf.mp4  \n",
            "  inflating: train_sample_videos/erqgqacbqe.mp4  \n",
            "  inflating: train_sample_videos/errocgcham.mp4  \n",
            "  inflating: train_sample_videos/esckbnkkvb.mp4  \n",
            "  inflating: train_sample_videos/esgftaficx.mp4  \n",
            "  inflating: train_sample_videos/esnntzzajv.mp4  \n",
            "  inflating: train_sample_videos/esxrvsgpvb.mp4  \n",
            "  inflating: train_sample_videos/esyhwdfnxs.mp4  \n",
            "  inflating: train_sample_videos/esyrimvzsa.mp4  \n",
            "  inflating: train_sample_videos/etdcqxabww.mp4  \n",
            "  inflating: train_sample_videos/etejaapnxh.mp4  \n",
            "  inflating: train_sample_videos/etmcruaihe.mp4  \n",
            "  inflating: train_sample_videos/etohcvnzbj.mp4  \n",
            "  inflating: train_sample_videos/eudeqjhdfd.mp4  \n",
            "  inflating: train_sample_videos/eukvucdetx.mp4  \n",
            "  inflating: train_sample_videos/metadata.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "e9AeOEm1KwpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xBsDaZkfKzKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxRdDCakadEm"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = '/content/train/train_sample_videos/'\n",
        "TMP_DIR = '/content/train/tmp/'\n",
        "ZIP_NAME = 'dfdc_train_faces_sample.zip'\n",
        "METADATA_PATH = TRAIN_DIR + 'metadata.json'\n",
        "\n",
        "SCALE = 0.25\n",
        "N_FRAMES = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet-pytorch > /dev/null 2>&1\n",
        "!apt install zip > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "3qi8OW_9K0kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import glob\n",
        "# import json\n",
        "# import torch\n",
        "# import cv2\n",
        "# from PIL import Image\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from tqdm.notebook import tqdm\n",
        "# from facenet_pytorch import MTCNN\n",
        "\n",
        "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "# print(f'Running on device: {device}')"
      ],
      "metadata": {
        "id": "V6AZcWD2K2eS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing as mp\n",
        "\n",
        "INPUT_DIR = '/kaggle/input/'\n",
        "SAVE_PATH = '/kaggle/working/resnet50.pth' # The location where the model should be saved.\n",
        "PRETRAINED_MODEL_PATH = ''\n",
        "\n",
        "N_FACES = 5\n",
        "TEST_SIZE = 0.3\n",
        "RANDOM_STATE = 123\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = mp.cpu_count()\n",
        "\n",
        "WARM_UP_EPOCHS = 10\n",
        "WARM_UP_LR = 1e-4\n",
        "FINE_TUNE_EPOCHS = 100\n",
        "FINE_TUNE_LR = 1e-6\n",
        "\n",
        "THRESHOLD = 0.5\n",
        "EPSILON = 1e-7"
      ],
      "metadata": {
        "id": "otrqQiwGK5dt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here i'm using formulas according to bayesian neural network as few values i was geeting nan, to overcome that issue,I m using BNN"
      ],
      "metadata": {
        "id": "eJsCsmScMu3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1(preds, labels):\n",
        "    labels = np.array(labels, dtype=np.uint8)\n",
        "    preds = (np.array(preds) >= THRESHOLD).astype(np.uint8)\n",
        "    tp = np.count_nonzero(np.logical_and(labels, preds))\n",
        "    tn = np.count_nonzero(np.logical_not(np.logical_or(labels, preds)))\n",
        "    fp = np.count_nonzero(np.logical_not(labels)) - tn\n",
        "    fn = np.count_nonzero(labels) - tp\n",
        "    precision = tp / (tp + fp + EPSILON)\n",
        "    recall = tp / (tp + fn + EPSILON)\n",
        "    f1 = (2 * precision * recall) / (precision + recall + EPSILON)\n",
        "\n",
        "    return f1"
      ],
      "metadata": {
        "id": "KRZLTPAFLt4F"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "xZLA0jdehhvB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def train_the_model(model, criterion, optimizer, epochs, train_dataloader, val_dataloader, best_val_loss=1e7, best_val_logloss=1e7, save_the_best_on='val_loss'):\n",
        "\n",
        "  losses = np.zeros(epochs)\n",
        "  val_losses = np.zeros(epochs)\n",
        "  loglosses = np.zeros(epochs)\n",
        "  val_loglosses = np.zeros(epochs)\n",
        "  f1_scores = np.zeros(epochs)\n",
        "  val_f1_scores = np.zeros(epochs)\n",
        "  best_model_state_dict = None\n",
        "  best_optimizer_state_dict = None\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    batch_losses = []\n",
        "    # Training loop within the epoch\n",
        "    for sample_batched in tqdm(train_dataloader):\n",
        "      with tf.GradientTape() as tape:\n",
        "        # Make prediction\n",
        "        y_pred = model(sample_batched['faces'])\n",
        "        # Compute loss\n",
        "        loss = criterion(y_pred, sample_batched['label'])\n",
        "      batch_losses.append(loss.numpy())\n",
        "\n",
        "      # Backpropagation and update weights\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      # Calculate and display training metrics\n",
        "      # (F1 score calculation might need adjustment for TensorFlow)\n",
        "      loglosses[epoch] = calculate_logloss(y_pred, sample_batched['label'])  # Assuming calculate_logloss is compatible with TensorFlow tensors\n",
        "      f1_scores[epoch] = calculate_f1(y_pred.numpy(), sample_batched['label'].numpy())  # Assuming calculate_f1 works with NumPy arrays\n",
        "\n",
        "    losses[epoch] = np.mean(batch_losses)\n",
        "\n",
        "    # Validation loop\n",
        "    val_batch_losses = []\n",
        "    for sample_batched in val_dataloader:\n",
        "      # Make prediction and compute loss\n",
        "      y_pred = model(sample_batched['faces'])\n",
        "      val_loss = criterion(y_pred, sample_batched['label'])\n",
        "      val_batch_losses.append(val_loss.numpy())\n",
        "\n",
        "      # Calculate and display validation metrics\n",
        "      val_loglosses[epoch] = calculate_logloss(y_pred, sample_batched['label'])  # Assuming calculate_logloss is compatible with TensorFlow tensors\n",
        "      val_f1_scores[epoch] = calculate_f1(y_pred.numpy(), sample_batched['label'].numpy())  # Assuming calculate_f1 works with NumPy arrays\n",
        "\n",
        "    val_losses[epoch] = np.mean(val_batch_losses)\n",
        "    print(f'loss: {losses[epoch]} | val loss: {val_losses[epoch]} | f1: {f1_scores[epoch]} | val f1: {val_f1_scores[epoch]} | log loss: {loglosses[epoch]} | val log loss: {val_loglosses[epoch]}')\n",
        "\n",
        "    # Update best model/optimizer if validation loss improves\n",
        "    if val_losses[epoch] < best_val_loss:\n",
        "      best_val_loss = val_losses[epoch]\n",
        "      if save_the_best_on == 'val_loss':\n",
        "        print('Found a better checkpoint!')\n",
        "        best_model_state_dict = model.get_weights()\n",
        "        best_optimizer_state_dict = optimizer.get\n",
        "\n",
        "\n",
        "    return losses, val_losses, loglosses, val_loglosses, f1_scores, val_f1_scores, best_val_loss, best_val_logloss, best_model_state_dict, best_optimizer_state_dict\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B_XPW4Q_Ubdc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(\n",
        "    losses,\n",
        "    val_losses,\n",
        "    loglosses,\n",
        "    val_loglosses,\n",
        "    f1_scores,\n",
        "    val_f1_scores\n",
        "):\n",
        "    fig = plt.figure(figsize=(16, 8))\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "    ax.plot(np.arange(1, len(losses) + 1), losses)\n",
        "    ax.plot(np.arange(1, len(val_losses) + 1), val_losses)\n",
        "    ax.set_xlabel('epoch', fontsize='xx-large')\n",
        "    ax.set_ylabel('focal loss', fontsize='xx-large')\n",
        "    ax.legend(\n",
        "        ['loss', 'val loss'],\n",
        "        loc='upper right',\n",
        "        fontsize='xx-large',\n",
        "        shadow=True\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 8))\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "    ax.plot(np.arange(1, len(loglosses) + 1), loglosses)\n",
        "    ax.plot(np.arange(1, len(val_loglosses) + 1), val_loglosses)\n",
        "    ax.set_xlabel('epoch', fontsize='xx-large')\n",
        "    ax.set_ylabel('log loss', fontsize='xx-large')\n",
        "    ax.legend(\n",
        "        ['log loss', 'val log loss'],\n",
        "        loc='upper right',\n",
        "        fontsize='xx-large',\n",
        "        shadow=True\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 8))\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "    ax.plot(np.arange(1, len(f1_scores) + 1), f1_scores)\n",
        "    ax.plot(np.arange(1, len(val_f1_scores) + 1), val_f1_scores)\n",
        "    ax.set_xlabel('epoch', fontsize='xx-large')\n",
        "    ax.set_ylabel('f1 score', fontsize='xx-large')\n",
        "    ax.legend(\n",
        "        ['f1', 'val f1'],\n",
        "        loc='upper left',\n",
        "        fontsize='xx-large',\n",
        "        shadow=True\n",
        "    )\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "IG3Q88AJmwkK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class DeepfakeClassifier(tf.keras.Model):\n",
        "  def __init__(self, encoder, in_channels=3, num_classes=1):\n",
        "    super(DeepfakeClassifier, self).__init__()\n",
        "    self.encoder = encoder\n",
        "\n",
        "    # Modify input layer\n",
        "    self.conv1 = tf.keras.layers.Conv2D(\n",
        "        filters=64, kernel_size=7, strides=2, padding=\"same\", input_shape=(None, None, in_channels), use_bias=False\n",
        "    )\n",
        "\n",
        "    # Modify output layer\n",
        "    self.fc = tf.keras.layers.Dense(num_classes, activation=\"sigmoid\")\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.encoder(x)\n",
        "    return x\n",
        "\n",
        "  def freeze_all_layers(self):\n",
        "    for layer in self.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "  def freeze_middle_layers(self):\n",
        "    self.freeze_all_layers()\n",
        "    self.conv1.trainable = True\n",
        "    self.fc.trainable = True\n",
        "\n",
        "  def unfreeze_all_layers(self):\n",
        "    for layer in self.layers:\n",
        "      layer.trainable = True"
      ],
      "metadata": {
        "id": "pTzp9e_9fPO_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceDataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, img_dirs, labels, n_faces=1, preprocess=None):\n",
        "        self.img_dirs = img_dirs\n",
        "        self.labels = labels\n",
        "        self.n_faces = n_faces\n",
        "        self.preprocess = preprocess\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_dirs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_dir = self.img_dirs[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        face_paths = glob(f'{img_dir}/*.png')\n",
        "\n",
        "        if len(face_paths) >= self.n_faces:\n",
        "            sample = tf.random.choice(face_paths, self.n_faces, replace=False)\n",
        "        else:\n",
        "            sample = tf.random.choice(face_paths, self.n_faces, replace=True)\n",
        "\n",
        "        faces = []\n",
        "        for face_path in sample.numpy():\n",
        "            face = cv2.imread(face_path, cv2.IMREAD_COLOR)  # Ensure color reading\n",
        "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # TensorFlow-specific image loading and preprocessing\n",
        "            face = load_img(face, target_size=(face.shape[0], face.shape[1]))\n",
        "            face = img_to_array(face)\n",
        "            if self.preprocess is not None:\n",
        "                face = self.preprocess(tf.expand_dims(face, axis=0))['image'][0]\n",
        "\n",
        "            faces.append(face)\n",
        "\n",
        "        faces = np.concatenate(faces, axis=-1)  # Concatenate along channels\n",
        "        faces = tf.convert_to_tensor(faces.transpose(2, 0, 1))  # Efficient transposing\n",
        "\n",
        "        return {'faces': faces, 'label': tf.cast(label, tf.float32)}\n",
        "\n",
        "\n",
        "\n",
        "class FaceValDataset(tf.data.Dataset):\n",
        "\n",
        "    def __init__(self, img_dirs, labels, n_faces=1, preprocess=None):\n",
        "        self.img_dirs = img_dirs\n",
        "        self.labels = labels\n",
        "        self.n_faces = n_faces\n",
        "        self.preprocess = preprocess\n",
        "\n",
        "    def _parse_function(self, sample):\n",
        "        img_dir, label = sample\n",
        "\n",
        "        face_paths = tf.strings.glob(f'{img_dir}/*.png')\n",
        "\n",
        "        # Extract face indices efficiently using tf.strings\n",
        "        face_indices = tf.strings.split(\n",
        "            tf.strings.split(face_paths, sep='/')[-1], sep='.'\n",
        "        )[0][..., 0]\n",
        "        max_idx = tf.cast(tf.math.reduce_max(tf.strings.to_number(face_indices, tf.uint32)), tf.uint32)\n",
        "\n",
        "        # Efficiently select faces with a stride\n",
        "        strides = tf.range(self.n_faces) * tf.cast(\n",
        "            tf.math.ceil(max_idx + 1 / (self.n_faces**2)), tf.float32\n",
        "        )\n",
        "        sample_indices = tf.cast(tf.math.floor(strides), tf.int32)\n",
        "\n",
        "        selected_paths = []\n",
        "        for idx in sample_indices:\n",
        "            paths = tf.strings.glob(f'{img_dir}/{idx}*.png')\n",
        "            selected_paths.append(paths)\n",
        "\n",
        "        selected_paths = tf.concat(selected_paths, axis=0)\n",
        "        selected_paths = tf.gather(selected_paths, tf.range(self.n_faces))  # Top n_faces\n",
        "\n",
        "        faces = []\n",
        "        for selected_path in selected_paths:\n",
        "            img = tf.io.read_file(selected_path)\n",
        "            img = tf.image.decode_png(img, channels=3)  # Ensure color reading\n",
        "            img = tf.cast(img, tf.float32)\n",
        "            img = tf.image.resize(img, (img.shape[0], img.shape[1]))  # Resize if needed\n",
        "            img = tf.cast(tf.image.rgb_to_hsv(img), tf.float32)  # Example preprocessing\n",
        "\n",
        "            faces.append(img)\n",
        "\n",
        "        if self.preprocess is not None:\n",
        "            faces = tf.stack(faces)\n",
        "            faces = self.preprocess(tf.expand_dims(faces, axis=0))['image']\n",
        "            faces = tf.squeeze(faces, axis=0)  # Remove unnecessary dimension\n",
        "\n",
        "        faces = tf.transpose(tf.concat(faces, axis=-1), perm=[2, 0, 1])\n",
        "\n",
        "        return {'faces': faces, 'label': tf.cast(label, tf.float32)}\n",
        "\n",
        "    def __iter__(self):\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((self.img_dirs, self.labels))\n",
        "        return dataset.map(self._parse_function)\n",
        "\n"
      ],
      "metadata": {
        "id": "sBPCuXM-m-MR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "class FocalLoss(tf.keras.losses.Loss):\n",
        "\n",
        "    def __init__(self, gamma=2.0, alpha=None, from_logits=True):\n",
        "        super(FocalLoss, self).__init__(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_MEAN)\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.from_logits = from_logits\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        \"\"\"Focal loss with support for weighting and handling logits.\"\"\"\n",
        "        if self.from_logits:\n",
        "            y_pred = tf.nn.sigmoid(y_pred)  # Convert logits to probabilities\n",
        "\n",
        "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = tf.where(tf.equal(y_true, 1), self.alpha, 1.0 - self.alpha)\n",
        "            alpha_f = tf.where(tf.equal(y_true, 0), self.alpha, 1.0 - self.alpha)\n",
        "            cl = (-alpha_t * K.log(pt_1)) * ((1 - pt_1) ** self.gamma)\n",
        "            cf = (-alpha_f * K.log(1.0 - pt_0)) * (pt_0 ** self.gamma)\n",
        "        else:\n",
        "            cl = (-K.log(pt_1)) * ((1 - pt_1) ** self.gamma)\n",
        "            cf = (-K.log(1.0 - pt_0)) * (pt_0 ** self.gamma)\n",
        "\n",
        "        loss = cl + cf\n",
        "        return self.reduction(loss)\n"
      ],
      "metadata": {
        "id": "PuwLXRz6nAh5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "12m4uuCdWd1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.io.gfile as gfile\n",
        "all_train_dirs = gfile.glob(INPUT_DIR + '/train_sample_videos')\n",
        "all_train_dirs = sorted(all_train_dirs)\n",
        "for i, train_dir in enumerate(all_train_dirs):\n",
        "  tf.print('[{:02}]'.format(i), train_dir)\n"
      ],
      "metadata": {
        "id": "eg-8scX0iqhq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Z_Sfe7djtJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.io.gfile as gfile\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "def _parse_csv(filename):\n",
        "  \"\"\"Reads a CSV file using tf.data.TextLineDataset and pandas.\"\"\"\n",
        "  try:\n",
        "    dataset = tf.data.TextLineDataset(filename)\n",
        "    df = pd.read_csv(dataset.skip(1))  # Skip header row\n",
        "    return df\n",
        "  except Exception as e:\n",
        "    print(f\"Error reading CSV: {filename} - {e}\")\n",
        "    return None  # Or handle the error differently\n",
        "\n",
        "# Ensure path consistency (replace with your actual directory)\n",
        "INPUT_DIR = '/content'\n",
        "\n",
        "# Find all train directories within the specified path\n",
        "all_train_dirs = sorted(gfile.glob(f'{INPUT_DIR}/train_sample_videos/*'))\n",
        "\n",
        "# Print the contents of all_train_dirs to check for directories\n",
        "print(\"Found directories:\")\n",
        "for train_dir in all_train_dirs:\n",
        "  print(train_dir)\n",
        "\n",
        "# Check if any directories were found\n",
        "if not all_train_dirs:\n",
        "  print(\"No directories found in train_sample_videos. Check the path or file structure.\")\n",
        "  exit()  # Terminate execution if no directories found\n",
        "\n",
        "import pandas as pd\n",
        "all_dataframes = []\n",
        "for train_dir in all_train_dirs:\n",
        "  #print(train_dir)\n",
        "  # metadata_path = os.path.join(train_dir, 'metadata.csv')\n",
        "  metadata_path = '/content/metadata.csv'\n",
        "  # df = _parse_csv(metadata_path)\n",
        "  df = pd.read_csv(metadata_path,names=['filename','label','split','original'],header=1)\n",
        "  # print(df.head())\n",
        "  # print(df.columns)\n",
        "  if df is not None:\n",
        "    df['path'] = df['filename'].apply(lambda x: os.path.join(train_dir, x.split('.')[0]))\n",
        "    all_dataframes.append(df)\n",
        "  else:\n",
        "    print(f\"Error reading CSV: {metadata_path}\")\n",
        "\n",
        "if all_dataframes:\n",
        "  train_df = pd.concat(all_dataframes, ignore_index=True, sort=False)\n",
        "  print(\"Successfully loaded dataframes. Now you can use the 'train_df' for further processing.\")\n",
        "else:\n",
        "  print(\"No DataFrames to concatenate. Check for errors or empty directories.\")\n"
      ],
      "metadata": {
        "id": "2-GvRr1HirQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b5bbb72-1a22-4ea4-816b-ae2b765eca87"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found directories:\n",
            "/content/train_sample_videos/aagfhgtpmv.mp4\n",
            "/content/train_sample_videos/aapnvogymq.mp4\n",
            "/content/train_sample_videos/abarnvbtwb.mp4\n",
            "/content/train_sample_videos/abofeumbvv.mp4\n",
            "/content/train_sample_videos/abqwwspghj.mp4\n",
            "/content/train_sample_videos/acifjvzvpm.mp4\n",
            "/content/train_sample_videos/acqfdwsrhi.mp4\n",
            "/content/train_sample_videos/acxnxvbsxk.mp4\n",
            "/content/train_sample_videos/acxwigylke.mp4\n",
            "/content/train_sample_videos/aczrgyricp.mp4\n",
            "/content/train_sample_videos/adhsbajydo.mp4\n",
            "/content/train_sample_videos/adohikbdaz.mp4\n",
            "/content/train_sample_videos/adylbeequz.mp4\n",
            "/content/train_sample_videos/aelfnikyqj.mp4\n",
            "/content/train_sample_videos/aelzhcnwgf.mp4\n",
            "/content/train_sample_videos/aettqgevhz.mp4\n",
            "/content/train_sample_videos/aevrfsexku.mp4\n",
            "/content/train_sample_videos/afoovlsmtx.mp4\n",
            "/content/train_sample_videos/agdkmztvby.mp4\n",
            "/content/train_sample_videos/agqphdxmwt.mp4\n",
            "/content/train_sample_videos/agrmhtjdlk.mp4\n",
            "/content/train_sample_videos/ahbweevwpv.mp4\n",
            "/content/train_sample_videos/ahdbuwqxit.mp4\n",
            "/content/train_sample_videos/ahfazfbntc.mp4\n",
            "/content/train_sample_videos/ahqqqilsxt.mp4\n",
            "/content/train_sample_videos/aipfdnwpoo.mp4\n",
            "/content/train_sample_videos/ajqslcypsw.mp4\n",
            "/content/train_sample_videos/ajwpjhrbcv.mp4\n",
            "/content/train_sample_videos/aklqzsddfl.mp4\n",
            "/content/train_sample_videos/aknbdpmgua.mp4\n",
            "/content/train_sample_videos/aknmpoonls.mp4\n",
            "/content/train_sample_videos/akvmwkdyuv.mp4\n",
            "/content/train_sample_videos/akxoopqjqz.mp4\n",
            "/content/train_sample_videos/akzbnazxtz.mp4\n",
            "/content/train_sample_videos/aladcziidp.mp4\n",
            "/content/train_sample_videos/alaijyygdv.mp4\n",
            "/content/train_sample_videos/alninxcyhg.mp4\n",
            "/content/train_sample_videos/altziddtxi.mp4\n",
            "/content/train_sample_videos/alvgwypubw.mp4\n",
            "/content/train_sample_videos/amaivqofda.mp4\n",
            "/content/train_sample_videos/amowujxmzc.mp4\n",
            "/content/train_sample_videos/andaxzscny.mp4\n",
            "/content/train_sample_videos/aneclqfpbt.mp4\n",
            "/content/train_sample_videos/anpuvshzoo.mp4\n",
            "/content/train_sample_videos/aorjvbyxhw.mp4\n",
            "/content/train_sample_videos/apatcsqejh.mp4\n",
            "/content/train_sample_videos/apgjqzkoma.mp4\n",
            "/content/train_sample_videos/apogckdfrz.mp4\n",
            "/content/train_sample_videos/aqpnvjhuzw.mp4\n",
            "/content/train_sample_videos/arkroixhey.mp4\n",
            "/content/train_sample_videos/arlmiizoob.mp4\n",
            "/content/train_sample_videos/arrhsnjqku.mp4\n",
            "/content/train_sample_videos/asaxgevnnp.mp4\n",
            "/content/train_sample_videos/asdpeebotb.mp4\n",
            "/content/train_sample_videos/aslsvlvpth.mp4\n",
            "/content/train_sample_videos/asmpfjfzif.mp4\n",
            "/content/train_sample_videos/asvcrfdpnq.mp4\n",
            "/content/train_sample_videos/atkdltyyen.mp4\n",
            "/content/train_sample_videos/atvmxvwyns.mp4\n",
            "/content/train_sample_videos/atxvxouljq.mp4\n",
            "/content/train_sample_videos/atyntldecu.mp4\n",
            "/content/train_sample_videos/atzdznmder.mp4\n",
            "/content/train_sample_videos/aufmsmnoye.mp4\n",
            "/content/train_sample_videos/augtsuxpzc.mp4\n",
            "/content/train_sample_videos/avfitoutyn.mp4\n",
            "/content/train_sample_videos/avgiuextiz.mp4\n",
            "/content/train_sample_videos/avibnnhwhp.mp4\n",
            "/content/train_sample_videos/avmjormvsx.mp4\n",
            "/content/train_sample_videos/avnqydkqjj.mp4\n",
            "/content/train_sample_videos/avssvvsdhz.mp4\n",
            "/content/train_sample_videos/avtycwsgyb.mp4\n",
            "/content/train_sample_videos/avvdgsennp.mp4\n",
            "/content/train_sample_videos/avywawptfc.mp4\n",
            "/content/train_sample_videos/awhmfnnjih.mp4\n",
            "/content/train_sample_videos/awnwkrqibf.mp4\n",
            "/content/train_sample_videos/awukslzjra.mp4\n",
            "/content/train_sample_videos/axczxisdtb.mp4\n",
            "/content/train_sample_videos/axntxmycwd.mp4\n",
            "/content/train_sample_videos/axoygtekut.mp4\n",
            "/content/train_sample_videos/axwgcsyphv.mp4\n",
            "/content/train_sample_videos/axwovszumc.mp4\n",
            "/content/train_sample_videos/aybgughjxh.mp4\n",
            "/content/train_sample_videos/aybumesmpk.mp4\n",
            "/content/train_sample_videos/ayqvfdhslr.mp4\n",
            "/content/train_sample_videos/aytzyidmgs.mp4\n",
            "/content/train_sample_videos/azpuxunqyo.mp4\n",
            "/content/train_sample_videos/azsmewqghg.mp4\n",
            "/content/train_sample_videos/bahdpoesir.mp4\n",
            "/content/train_sample_videos/bbhpvrmbse.mp4\n",
            "/content/train_sample_videos/bbhtdfuqxq.mp4\n",
            "/content/train_sample_videos/bbvgxeczei.mp4\n",
            "/content/train_sample_videos/bchnbulevv.mp4\n",
            "/content/train_sample_videos/bctvsmddgq.mp4\n",
            "/content/train_sample_videos/bdbhekrrwo.mp4\n",
            "/content/train_sample_videos/bddjdhzfze.mp4\n",
            "/content/train_sample_videos/bdgipnyobr.mp4\n",
            "/content/train_sample_videos/bdnaqemxmr.mp4\n",
            "/content/train_sample_videos/bdxuhamuqx.mp4\n",
            "/content/train_sample_videos/beboztfcme.mp4\n",
            "/content/train_sample_videos/bejhvclboh.mp4\n",
            "/content/train_sample_videos/benmsfzfaz.mp4\n",
            "/content/train_sample_videos/beyebyhrph.mp4\n",
            "/content/train_sample_videos/bffwsjxghk.mp4\n",
            "/content/train_sample_videos/bgaogsjehq.mp4\n",
            "/content/train_sample_videos/bggsurpgpr.mp4\n",
            "/content/train_sample_videos/bghphrsfxf.mp4\n",
            "/content/train_sample_videos/bgmlwsoamc.mp4\n",
            "/content/train_sample_videos/bguwlyazau.mp4\n",
            "/content/train_sample_videos/bgvhtpzknn.mp4\n",
            "/content/train_sample_videos/bgwmmujlmc.mp4\n",
            "/content/train_sample_videos/bhaaboftbc.mp4\n",
            "/content/train_sample_videos/bhbdugnurr.mp4\n",
            "/content/train_sample_videos/bhpwpydzpo.mp4\n",
            "/content/train_sample_videos/bhsluedavd.mp4\n",
            "/content/train_sample_videos/bilnggbxgu.mp4\n",
            "/content/train_sample_videos/bjjbwsqjir.mp4\n",
            "/content/train_sample_videos/bjkmjilrxp.mp4\n",
            "/content/train_sample_videos/bjsmaqefoi.mp4\n",
            "/content/train_sample_videos/bkmdzhfzfh.mp4\n",
            "/content/train_sample_videos/bkvetcojbt.mp4\n",
            "/content/train_sample_videos/bkwxhglwct.mp4\n",
            "/content/train_sample_videos/blpchvmhxx.mp4\n",
            "/content/train_sample_videos/blzydqdfem.mp4\n",
            "/content/train_sample_videos/bmbbkwmxqj.mp4\n",
            "/content/train_sample_videos/bmehkyanbj.mp4\n",
            "/content/train_sample_videos/bmhvktyiwp.mp4\n",
            "/content/train_sample_videos/bmioepcpsx.mp4\n",
            "/content/train_sample_videos/bmjmjmbglm.mp4\n",
            "/content/train_sample_videos/bmjzrlszhi.mp4\n",
            "/content/train_sample_videos/bnbuonyoje.mp4\n",
            "/content/train_sample_videos/bndybcqhfr.mp4\n",
            "/content/train_sample_videos/bnjcdrfuov.mp4\n",
            "/content/train_sample_videos/bntlodcfeg.mp4\n",
            "/content/train_sample_videos/bofqajtwve.mp4\n",
            "/content/train_sample_videos/boovltmuwi.mp4\n",
            "/content/train_sample_videos/bopqhhalml.mp4\n",
            "/content/train_sample_videos/bourlmzsio.mp4\n",
            "/content/train_sample_videos/bpapbctoao.mp4\n",
            "/content/train_sample_videos/bpwzipqtxf.mp4\n",
            "/content/train_sample_videos/bpxckdzddv.mp4\n",
            "/content/train_sample_videos/bqdjzqhcft.mp4\n",
            "/content/train_sample_videos/bqeiblbxtl.mp4\n",
            "/content/train_sample_videos/bqhtpqmmqp.mp4\n",
            "/content/train_sample_videos/bqkdbcqjvb.mp4\n",
            "/content/train_sample_videos/bqnymlsayl.mp4\n",
            "/content/train_sample_videos/bqqpbzjgup.mp4\n",
            "/content/train_sample_videos/bqtuuwzdtr.mp4\n",
            "/content/train_sample_videos/brhalypwoo.mp4\n",
            "/content/train_sample_videos/brvqtabyxj.mp4\n",
            "/content/train_sample_videos/brwrlczjvi.mp4\n",
            "/content/train_sample_videos/bseamdrpbj.mp4\n",
            "/content/train_sample_videos/bsfmwclnqy.mp4\n",
            "/content/train_sample_videos/bsqgziaylx.mp4\n",
            "/content/train_sample_videos/btiysiskpf.mp4\n",
            "/content/train_sample_videos/btjlfpzbdu.mp4\n",
            "/content/train_sample_videos/btjwbtsgln.mp4\n",
            "/content/train_sample_videos/btmsngnqhv.mp4\n",
            "/content/train_sample_videos/btohlidmru.mp4\n",
            "/content/train_sample_videos/btugrnoton.mp4\n",
            "/content/train_sample_videos/btunxncpjh.mp4\n",
            "/content/train_sample_videos/btxlttbpkj.mp4\n",
            "/content/train_sample_videos/bulkxhhknf.mp4\n",
            "/content/train_sample_videos/bvgwelbeof.mp4\n",
            "/content/train_sample_videos/bvzjkezkms.mp4\n",
            "/content/train_sample_videos/bweezhfpzp.mp4\n",
            "/content/train_sample_videos/bwhlgysghg.mp4\n",
            "/content/train_sample_videos/bwipwzzxxu.mp4\n",
            "/content/train_sample_videos/bwuwstvsbw.mp4\n",
            "/content/train_sample_videos/bxzakyopjf.mp4\n",
            "/content/train_sample_videos/bydaidkpdp.mp4\n",
            "/content/train_sample_videos/byfenovjnf.mp4\n",
            "/content/train_sample_videos/byijojkdba.mp4\n",
            "/content/train_sample_videos/byofowlkki.mp4\n",
            "/content/train_sample_videos/byqzyxifza.mp4\n",
            "/content/train_sample_videos/byunigvnay.mp4\n",
            "/content/train_sample_videos/byyqectxqa.mp4\n",
            "/content/train_sample_videos/bzmdrafeex.mp4\n",
            "/content/train_sample_videos/bzythlfnhq.mp4\n",
            "/content/train_sample_videos/caifxvsozs.mp4\n",
            "/content/train_sample_videos/caqbrkogkb.mp4\n",
            "/content/train_sample_videos/cbbibzcoih.mp4\n",
            "/content/train_sample_videos/cbltdtxglo.mp4\n",
            "/content/train_sample_videos/ccfoszqabv.mp4\n",
            "/content/train_sample_videos/ccmonzqfrz.mp4\n",
            "/content/train_sample_videos/cdaxixbosp.mp4\n",
            "/content/train_sample_videos/cdbsbdymzd.mp4\n",
            "/content/train_sample_videos/cdphtzqrvp.mp4\n",
            "/content/train_sample_videos/cdyakrxkia.mp4\n",
            "/content/train_sample_videos/cepxysienc.mp4\n",
            "/content/train_sample_videos/cettndmvzl.mp4\n",
            "/content/train_sample_videos/ceymbecxnj.mp4\n",
            "/content/train_sample_videos/cferslmfwh.mp4\n",
            "/content/train_sample_videos/cffffbcywc.mp4\n",
            "/content/train_sample_videos/cfxkpiweqt.mp4\n",
            "/content/train_sample_videos/cfyduhpbps.mp4\n",
            "/content/train_sample_videos/cglxirfaey.mp4\n",
            "/content/train_sample_videos/cgvrgibpfo.mp4\n",
            "/content/train_sample_videos/chtapglbcj.mp4\n",
            "/content/train_sample_videos/chviwxsfhg.mp4\n",
            "/content/train_sample_videos/chzieimrwu.mp4\n",
            "/content/train_sample_videos/ciyoudyhly.mp4\n",
            "/content/train_sample_videos/cizlkenljw.mp4\n",
            "/content/train_sample_videos/ckbdwedgmc.mp4\n",
            "/content/train_sample_videos/ckjaibzfxa.mp4\n",
            "/content/train_sample_videos/ckkuyewywx.mp4\n",
            "/content/train_sample_videos/cknyxaqouy.mp4\n",
            "/content/train_sample_videos/cksanfsjhc.mp4\n",
            "/content/train_sample_videos/clihsshdkq.mp4\n",
            "/content/train_sample_videos/clrycekyst.mp4\n",
            "/content/train_sample_videos/cmbzllswnl.mp4\n",
            "/content/train_sample_videos/cmxcfkrjiv.mp4\n",
            "/content/train_sample_videos/cnilkgvfei.mp4\n",
            "/content/train_sample_videos/coadfnerlk.mp4\n",
            "/content/train_sample_videos/cobjrlugvp.mp4\n",
            "/content/train_sample_videos/covdcysmbi.mp4\n",
            "/content/train_sample_videos/cpjxareypw.mp4\n",
            "/content/train_sample_videos/cppdvdejkc.mp4\n",
            "/content/train_sample_videos/cprhtltsjp.mp4\n",
            "/content/train_sample_videos/cqfugiqupm.mp4\n",
            "/content/train_sample_videos/cqhngvpgyi.mp4\n",
            "/content/train_sample_videos/cqrskwiqng.mp4\n",
            "/content/train_sample_videos/crezycjqyk.mp4\n",
            "/content/train_sample_videos/crktehraph.mp4\n",
            "/content/train_sample_videos/crzfebnfgb.mp4\n",
            "/content/train_sample_videos/cthdnahrkh.mp4\n",
            "/content/train_sample_videos/ctpqeykqdp.mp4\n",
            "/content/train_sample_videos/cttqtsjvgn.mp4\n",
            "/content/train_sample_videos/ctzmavwror.mp4\n",
            "/content/train_sample_videos/curpwogllm.mp4\n",
            "/content/train_sample_videos/cuzrgrbvil.mp4\n",
            "/content/train_sample_videos/cvaksbpssm.mp4\n",
            "/content/train_sample_videos/cwbacdwrzo.mp4\n",
            "/content/train_sample_videos/cwqlvzefpg.mp4\n",
            "/content/train_sample_videos/cwrtyzndpx.mp4\n",
            "/content/train_sample_videos/cwsbspfzck.mp4\n",
            "/content/train_sample_videos/cwwandrkus.mp4\n",
            "/content/train_sample_videos/cxfujlvsuw.mp4\n",
            "/content/train_sample_videos/cxrfacemmq.mp4\n",
            "/content/train_sample_videos/cxttmymlbn.mp4\n",
            "/content/train_sample_videos/cyboodqqyr.mp4\n",
            "/content/train_sample_videos/cycacemkmt.mp4\n",
            "/content/train_sample_videos/cyclgfjdrv.mp4\n",
            "/content/train_sample_videos/cyxlcuyznd.mp4\n",
            "/content/train_sample_videos/czfunozvwp.mp4\n",
            "/content/train_sample_videos/czkdanyadc.mp4\n",
            "/content/train_sample_videos/czmqpxrqoh.mp4\n",
            "/content/train_sample_videos/dafhtipaml.mp4\n",
            "/content/train_sample_videos/dakiztgtnw.mp4\n",
            "/content/train_sample_videos/dakqwktlbi.mp4\n",
            "/content/train_sample_videos/dbhoxkblzx.mp4\n",
            "/content/train_sample_videos/dbhrpizyeq.mp4\n",
            "/content/train_sample_videos/dbnygxtwek.mp4\n",
            "/content/train_sample_videos/dboxtiehng.mp4\n",
            "/content/train_sample_videos/dbtbbhakdv.mp4\n",
            "/content/train_sample_videos/dbzcqmxzaj.mp4\n",
            "/content/train_sample_videos/dbzpcjntve.mp4\n",
            "/content/train_sample_videos/dcamvmuors.mp4\n",
            "/content/train_sample_videos/dcuiiorugd.mp4\n",
            "/content/train_sample_videos/ddepeddixj.mp4\n",
            "/content/train_sample_videos/ddhfabwpuz.mp4\n",
            "/content/train_sample_videos/ddjggcasdw.mp4\n",
            "/content/train_sample_videos/ddpvuimigj.mp4\n",
            "/content/train_sample_videos/ddqccgmtka.mp4\n",
            "/content/train_sample_videos/degpbqvcay.mp4\n",
            "/content/train_sample_videos/deywhkarol.mp4\n",
            "/content/train_sample_videos/deyyistcrd.mp4\n",
            "/content/train_sample_videos/dfbpceeaox.mp4\n",
            "/content/train_sample_videos/dgmevclvzy.mp4\n",
            "/content/train_sample_videos/dgxrqjdomn.mp4\n",
            "/content/train_sample_videos/dgzklxjmix.mp4\n",
            "/content/train_sample_videos/dhcndnuwta.mp4\n",
            "/content/train_sample_videos/dhcselezer.mp4\n",
            "/content/train_sample_videos/dhevettufk.mp4\n",
            "/content/train_sample_videos/dhjmzhrcav.mp4\n",
            "/content/train_sample_videos/dhkwmjxwrn.mp4\n",
            "/content/train_sample_videos/dhoqofwoxa.mp4\n",
            "/content/train_sample_videos/dhxctgyoqj.mp4\n",
            "/content/train_sample_videos/diomeixhrg.mp4\n",
            "/content/train_sample_videos/diopzaywor.mp4\n",
            "/content/train_sample_videos/diqraixiov.mp4\n",
            "/content/train_sample_videos/diuzrpqjli.mp4\n",
            "/content/train_sample_videos/djvtbgwdcc.mp4\n",
            "/content/train_sample_videos/djvutyvaio.mp4\n",
            "/content/train_sample_videos/djxdyjopjd.mp4\n",
            "/content/train_sample_videos/dkdwxmtpuo.mp4\n",
            "/content/train_sample_videos/dkhlttuvmx.mp4\n",
            "/content/train_sample_videos/dkrvorliqc.mp4\n",
            "/content/train_sample_videos/dkuayagnmc.mp4\n",
            "/content/train_sample_videos/dkwjwbwgey.mp4\n",
            "/content/train_sample_videos/dkzvdrzcnr.mp4\n",
            "/content/train_sample_videos/dlpoieqvfb.mp4\n",
            "/content/train_sample_videos/dlrsbscitn.mp4\n",
            "/content/train_sample_videos/dnexlwbcxq.mp4\n",
            "/content/train_sample_videos/dnhvalzvrt.mp4\n",
            "/content/train_sample_videos/dntkzzzcdh.mp4\n",
            "/content/train_sample_videos/dnyvfblxpm.mp4\n",
            "/content/train_sample_videos/doanjploai.mp4\n",
            "/content/train_sample_videos/dofusvhnib.mp4\n",
            "/content/train_sample_videos/dozyddhild.mp4\n",
            "/content/train_sample_videos/dptbnjnkdg.mp4\n",
            "/content/train_sample_videos/dptrzdvwpg.mp4\n",
            "/content/train_sample_videos/dqnyszdong.mp4\n",
            "/content/train_sample_videos/dqppxmoqdl.mp4\n",
            "/content/train_sample_videos/dqqtjcryjv.mp4\n",
            "/content/train_sample_videos/dqswpjoepo.mp4\n",
            "/content/train_sample_videos/dqzreruvje.mp4\n",
            "/content/train_sample_videos/drcyabprvt.mp4\n",
            "/content/train_sample_videos/drgjzlxzxj.mp4\n",
            "/content/train_sample_videos/drsakwyvqv.mp4\n",
            "/content/train_sample_videos/drtbksnpol.mp4\n",
            "/content/train_sample_videos/dsdoseflas.mp4\n",
            "/content/train_sample_videos/dsgpbgsrdm.mp4\n",
            "/content/train_sample_videos/dsjbknkujw.mp4\n",
            "/content/train_sample_videos/dsndhujjjb.mp4\n",
            "/content/train_sample_videos/dtbpmdqvao.mp4\n",
            "/content/train_sample_videos/dtocdfbwca.mp4\n",
            "/content/train_sample_videos/dubiroskqn.mp4\n",
            "/content/train_sample_videos/dulanfulol.mp4\n",
            "/content/train_sample_videos/duvyaxbzvp.mp4\n",
            "/content/train_sample_videos/duycddgtrl.mp4\n",
            "/content/train_sample_videos/duzuusuajr.mp4\n",
            "/content/train_sample_videos/dvakowbgbt.mp4\n",
            "/content/train_sample_videos/dvumqqhoac.mp4\n",
            "/content/train_sample_videos/dwediigjit.mp4\n",
            "/content/train_sample_videos/dxbqjxrhin.mp4\n",
            "/content/train_sample_videos/dxuliowugt.mp4\n",
            "/content/train_sample_videos/dxuplhwvig.mp4\n",
            "/content/train_sample_videos/dzieklokdr.mp4\n",
            "/content/train_sample_videos/dzqwgqewhu.mp4\n",
            "/content/train_sample_videos/dzvyfiarrq.mp4\n",
            "/content/train_sample_videos/dzwkmcwkwl.mp4\n",
            "/content/train_sample_videos/dzyuwjkjui.mp4\n",
            "/content/train_sample_videos/eahlqmfvtj.mp4\n",
            "/content/train_sample_videos/eajlrktemq.mp4\n",
            "/content/train_sample_videos/ebchwmwayp.mp4\n",
            "/content/train_sample_videos/ebebgmtlcu.mp4\n",
            "/content/train_sample_videos/ebeknhudxq.mp4\n",
            "/content/train_sample_videos/ebkzwjgjhq.mp4\n",
            "/content/train_sample_videos/ebywfrmhtd.mp4\n",
            "/content/train_sample_videos/eckvhdusax.mp4\n",
            "/content/train_sample_videos/ecnihjlfyt.mp4\n",
            "/content/train_sample_videos/ecujsjhscd.mp4\n",
            "/content/train_sample_videos/ecuvtoltue.mp4\n",
            "/content/train_sample_videos/ecwaxgutkc.mp4\n",
            "/content/train_sample_videos/eczrseixwq.mp4\n",
            "/content/train_sample_videos/edyncaijwx.mp4\n",
            "/content/train_sample_videos/eebrkicpry.mp4\n",
            "/content/train_sample_videos/eebserckhh.mp4\n",
            "/content/train_sample_videos/eejswgycjc.mp4\n",
            "/content/train_sample_videos/eekozbeafq.mp4\n",
            "/content/train_sample_videos/eepezmygaq.mp4\n",
            "/content/train_sample_videos/eeyhxisdfh.mp4\n",
            "/content/train_sample_videos/efdyrflcpg.mp4\n",
            "/content/train_sample_videos/efwfxwwlbw.mp4\n",
            "/content/train_sample_videos/egbbcxcuqy.mp4\n",
            "/content/train_sample_videos/eggbjzxnmg.mp4\n",
            "/content/train_sample_videos/egghxjjmfg.mp4\n",
            "/content/train_sample_videos/ehbnclaukr.mp4\n",
            "/content/train_sample_videos/ehccixxzoe.mp4\n",
            "/content/train_sample_videos/ehdkmxgtxh.mp4\n",
            "/content/train_sample_videos/ehevsxtecd.mp4\n",
            "/content/train_sample_videos/ehfiekigla.mp4\n",
            "/content/train_sample_videos/ehieahnhte.mp4\n",
            "/content/train_sample_videos/ehtdtkmmli.mp4\n",
            "/content/train_sample_videos/eiriyukqqy.mp4\n",
            "/content/train_sample_videos/eivxffliio.mp4\n",
            "/content/train_sample_videos/eiwopxzjfn.mp4\n",
            "/content/train_sample_videos/eixwxvxbbn.mp4\n",
            "/content/train_sample_videos/ejkqesyvam.mp4\n",
            "/content/train_sample_videos/ekcrtigpab.mp4\n",
            "/content/train_sample_videos/ekhacizpah.mp4\n",
            "/content/train_sample_videos/ekkdjkirzq.mp4\n",
            "/content/train_sample_videos/elginszwtk.mp4\n",
            "/content/train_sample_videos/ellavthztb.mp4\n",
            "/content/train_sample_videos/elvvackpjh.mp4\n",
            "/content/train_sample_videos/emaalmsonj.mp4\n",
            "/content/train_sample_videos/emfbhytfhc.mp4\n",
            "/content/train_sample_videos/emgjphonqb.mp4\n",
            "/content/train_sample_videos/ensyyivobf.mp4\n",
            "/content/train_sample_videos/eoewqcpbgt.mp4\n",
            "/content/train_sample_videos/eprybmbpba.mp4\n",
            "/content/train_sample_videos/epymyyiblu.mp4\n",
            "/content/train_sample_videos/eqjscdagiv.mp4\n",
            "/content/train_sample_videos/eqnoqyfquo.mp4\n",
            "/content/train_sample_videos/eqvuznuwsa.mp4\n",
            "/content/train_sample_videos/erlvuvjsjf.mp4\n",
            "/content/train_sample_videos/erqgqacbqe.mp4\n",
            "/content/train_sample_videos/errocgcham.mp4\n",
            "/content/train_sample_videos/esckbnkkvb.mp4\n",
            "/content/train_sample_videos/esgftaficx.mp4\n",
            "/content/train_sample_videos/esnntzzajv.mp4\n",
            "/content/train_sample_videos/esxrvsgpvb.mp4\n",
            "/content/train_sample_videos/esyhwdfnxs.mp4\n",
            "/content/train_sample_videos/esyrimvzsa.mp4\n",
            "/content/train_sample_videos/etdcqxabww.mp4\n",
            "/content/train_sample_videos/etejaapnxh.mp4\n",
            "/content/train_sample_videos/etmcruaihe.mp4\n",
            "/content/train_sample_videos/etohcvnzbj.mp4\n",
            "/content/train_sample_videos/eudeqjhdfd.mp4\n",
            "/content/train_sample_videos/eukvucdetx.mp4\n",
            "/content/train_sample_videos/metadata.json\n",
            "Successfully loaded dataframes. Now you can use the 'train_df' for further processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "PsShYZ11nDS8",
        "outputId": "3c4df41e-ee8b-4bbd-98bf-49b8303d7ee0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              filename label  split        original  \\\n",
              "0       aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4   \n",
              "1       abarnvbtwb.mp4  REAL  train             NaN   \n",
              "2       abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4   \n",
              "3       abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4   \n",
              "4       acifjvzvpm.mp4  FAKE  train  kbvibjhfzo.mp4   \n",
              "...                ...   ...    ...             ...   \n",
              "159994  etejaapnxh.mp4  FAKE  train  wtreibcmgm.mp4   \n",
              "159995  etmcruaihe.mp4  FAKE  train  afoovlsmtx.mp4   \n",
              "159996  etohcvnzbj.mp4  FAKE  train  bdnaqemxmr.mp4   \n",
              "159997  eudeqjhdfd.mp4  REAL  train             NaN   \n",
              "159998  eukvucdetx.mp4  FAKE  train  gjypopglvi.mp4   \n",
              "\n",
              "                                                     path  \n",
              "0       /content/train_sample_videos/aagfhgtpmv.mp4/aa...  \n",
              "1       /content/train_sample_videos/aagfhgtpmv.mp4/ab...  \n",
              "2       /content/train_sample_videos/aagfhgtpmv.mp4/ab...  \n",
              "3       /content/train_sample_videos/aagfhgtpmv.mp4/ab...  \n",
              "4       /content/train_sample_videos/aagfhgtpmv.mp4/ac...  \n",
              "...                                                   ...  \n",
              "159994  /content/train_sample_videos/metadata.json/ete...  \n",
              "159995  /content/train_sample_videos/metadata.json/etm...  \n",
              "159996  /content/train_sample_videos/metadata.json/eto...  \n",
              "159997  /content/train_sample_videos/metadata.json/eud...  \n",
              "159998  /content/train_sample_videos/metadata.json/euk...  \n",
              "\n",
              "[159999 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b76a2d79-a112-41e2-b56e-2c964a7e0f86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "      <th>original</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aapnvogymq.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>jdubbvfswz.mp4</td>\n",
              "      <td>/content/train_sample_videos/aagfhgtpmv.mp4/aa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abarnvbtwb.mp4</td>\n",
              "      <td>REAL</td>\n",
              "      <td>train</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/train_sample_videos/aagfhgtpmv.mp4/ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abofeumbvv.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>atvmxvwyns.mp4</td>\n",
              "      <td>/content/train_sample_videos/aagfhgtpmv.mp4/ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abqwwspghj.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>qzimuostzz.mp4</td>\n",
              "      <td>/content/train_sample_videos/aagfhgtpmv.mp4/ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>acifjvzvpm.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>kbvibjhfzo.mp4</td>\n",
              "      <td>/content/train_sample_videos/aagfhgtpmv.mp4/ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159994</th>\n",
              "      <td>etejaapnxh.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>wtreibcmgm.mp4</td>\n",
              "      <td>/content/train_sample_videos/metadata.json/ete...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159995</th>\n",
              "      <td>etmcruaihe.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>afoovlsmtx.mp4</td>\n",
              "      <td>/content/train_sample_videos/metadata.json/etm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159996</th>\n",
              "      <td>etohcvnzbj.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>bdnaqemxmr.mp4</td>\n",
              "      <td>/content/train_sample_videos/metadata.json/eto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159997</th>\n",
              "      <td>eudeqjhdfd.mp4</td>\n",
              "      <td>REAL</td>\n",
              "      <td>train</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/train_sample_videos/metadata.json/eud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159998</th>\n",
              "      <td>eukvucdetx.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>gjypopglvi.mp4</td>\n",
              "      <td>/content/train_sample_videos/metadata.json/euk...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159999 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b76a2d79-a112-41e2-b56e-2c964a7e0f86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b76a2d79-a112-41e2-b56e-2c964a7e0f86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b76a2d79-a112-41e2-b56e-2c964a7e0f86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b58b2166-4e42-4fee-9307-77621003582c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b58b2166-4e42-4fee-9307-77621003582c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b58b2166-4e42-4fee-9307-77621003582c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()\n"
      ],
      "metadata": {
        "id": "1beLdWSkiteE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "7b111e82-7669-4185-eb37-7cc441e977ea"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         filename label  split        original  \\\n",
              "0  aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4   \n",
              "1  abarnvbtwb.mp4  REAL  train             NaN   \n",
              "2  abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4   \n",
              "3  abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4   \n",
              "4  acifjvzvpm.mp4  FAKE  train  kbvibjhfzo.mp4   \n",
              "\n",
              "                                                path  \n",
              "0  /content/train_sample_videos/aagfhgtpmv.mp4/aa...  \n",
              "1  /content/train_sample_videos/aagfhgtpmv.mp4/ab...  \n",
              "2  /content/train_sample_videos/aagfhgtpmv.mp4/ab...  \n",
              "3  /content/train_sample_videos/aagfhgtpmv.mp4/ab...  \n",
              "4  /content/train_sample_videos/aagfhgtpmv.mp4/ac...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09040bd0-2ab9-4869-8e70-da9ae5153fac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "      <th>original</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aapnvogymq.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>jdubbvfswz.mp4</td>\n",
              "      <td>/content/train_sample_videos/aagfhgtpmv.mp4/aa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abarnvbtwb.mp4</td>\n",
              "      <td>REAL</td>\n",
              "      <td>train</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/train_sample_videos/aagfhgtpmv.mp4/ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abofeumbvv.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>atvmxvwyns.mp4</td>\n",
              "      <td>/content/train_sample_videos/aagfhgtpmv.mp4/ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abqwwspghj.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>qzimuostzz.mp4</td>\n",
              "      <td>/content/train_sample_videos/aagfhgtpmv.mp4/ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>acifjvzvpm.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>kbvibjhfzo.mp4</td>\n",
              "      <td>/content/train_sample_videos/aagfhgtpmv.mp4/ac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09040bd0-2ab9-4869-8e70-da9ae5153fac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09040bd0-2ab9-4869-8e70-da9ae5153fac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09040bd0-2ab9-4869-8e70-da9ae5153fac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0d292374-c2ca-4155-99aa-3838cc415e6c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d292374-c2ca-4155-99aa-3838cc415e6c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0d292374-c2ca-4155-99aa-3838cc415e6c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "remove corrupt videos"
      ],
      "metadata": {
        "id": "8-F8qC2RizCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove empty folders\n",
        "train_df = train_df[train_df['path'].map(lambda x: os.path.exists(x))]"
      ],
      "metadata": {
        "id": "wtSpZlATiwea"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()\n"
      ],
      "metadata": {
        "id": "b8mhmNBIi8DK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "146f763b-f42f-4dae-d357-e80ee01d70ce"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [filename, label, split, original, path]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ab53224-dc95-4e64-9d4f-1f3028832d8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "      <th>original</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ab53224-dc95-4e64-9d4f-1f3028832d8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ab53224-dc95-4e64-9d4f-1f3028832d8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ab53224-dc95-4e64-9d4f-1f3028832d8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_train_df = pd.DataFrame(columns=['filename', 'label', 'split', 'original', 'path'])\n",
        "\n",
        "# for row_idx, row in tqdm(train_df.iterrows()):\n",
        "for row_idx in tqdm(train_df.index):\n",
        "    row = train_df.loc[row_idx]\n",
        "    img_dir = row['path']\n",
        "    face_paths = glob.glob(f'{img_dir}/*.png')\n",
        "\n",
        "    if len(face_paths) >= N_FACES: # Satisfy the minimum requirement for the number of faces\n",
        "        face_indices = [\n",
        "            path.split('/')[-1].split('.')[0].split('_')[0]\n",
        "            for path in face_paths\n",
        "        ]\n",
        "        max_idx = np.max(np.array(face_indices, dtype=np.uint32))\n",
        "\n",
        "        selected_paths = []\n",
        "\n",
        "        for i in range(N_FACES):\n",
        "            stride = int((max_idx + 1)/(N_FACES**2))\n",
        "            sample = np.linspace(i*stride, max_idx + i*stride, N_FACES).astype(int)\n",
        "\n",
        "            # Get faces\n",
        "            for idx in sample:\n",
        "                paths = glob.glob(f'{img_dir}/{idx}*.png')\n",
        "\n",
        "                selected_paths.extend(paths)\n",
        "                if len(selected_paths) >= N_FACES: # Get enough faces\n",
        "                    break\n",
        "\n",
        "            if len(selected_paths) >= N_FACES: # Get enough faces\n",
        "                valid_train_df = valid_train_df.append(row, ignore_index=True)\n",
        "                break\n"
      ],
      "metadata": {
        "id": "fX3lP3TEi9Z8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a476109d-98eb-4e2a-cd6a-8d203e473545"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_train_df.head()"
      ],
      "metadata": {
        "id": "eRELRIYqjL3W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bb1961ed-fa6d-41ad-be8e-5f1ea947d452"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [filename, label, split, original, path]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0a3219e-1b66-43cc-a04f-90d5a4396ab6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "      <th>original</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0a3219e-1b66-43cc-a04f-90d5a4396ab6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d0a3219e-1b66-43cc-a04f-90d5a4396ab6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d0a3219e-1b66-43cc-a04f-90d5a4396ab6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "valid_train_df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_train_df['label'].replace({'FAKE': 1, 'REAL': 0}, inplace=True)"
      ],
      "metadata": {
        "id": "FzxMu-0HjNTI"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_train_df.head()"
      ],
      "metadata": {
        "id": "3cuUCT1ojO8r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "65781eee-c63a-4b2f-997e-6c69269d2348"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [filename, label, split, original, path]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-477873a7-a0a8-40be-946e-ebd7476aaaee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "      <th>original</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-477873a7-a0a8-40be-946e-ebd7476aaaee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-477873a7-a0a8-40be-946e-ebd7476aaaee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-477873a7-a0a8-40be-946e-ebd7476aaaee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "valid_train_df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_count = valid_train_df.groupby('label').count()['filename']\n",
        "print(label_count)"
      ],
      "metadata": {
        "id": "C0o-w2J4jRDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214363c3-db15-48fd-cca2-5551a8e9c765"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], Name: filename, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = valid_train_df['path'].to_numpy()\n",
        "y = valid_train_df['label'].to_numpy()"
      ],
      "metadata": {
        "id": "qla6ZqmAjSc1"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
        "except ValueError as e:\n",
        "    print(f\"Error: Empty dataset. Skipping data splitting. {e}\")\n",
        "    # Handle the empty data situation here (e.g., collect more data)\n"
      ],
      "metadata": {
        "id": "_RQA5t29jTWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1a5daa-a2bf-4857-baf8-17d27a618bce"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Empty dataset. Skipping data splitting. With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Normalization\n",
        "\n",
        "# Create a Normalization layer with specified mean and std\n",
        "normalization_layer = Normalization(mean=[0.485, 0.456, 0.406], variance=[0.229**2, 0.224**2, 0.225**2])\n",
        "\n",
        "# Apply normalization during model definition\n",
        "model = tf.keras.Sequential([\n",
        "  normalization_layer,\n",
        "  # Other layers in your model\n",
        "])\n"
      ],
      "metadata": {
        "id": "9QLelLYsjV2k"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = FaceDataset(\n",
        "    img_dirs=X_train,\n",
        "    labels=y_train,\n",
        "    n_faces=N_FACES,\n",
        "    preprocess=preprocess\n",
        ")\n",
        "val_dataset = FaceValDataset(\n",
        "    img_dirs=X_val,\n",
        "    labels=y_val,\n",
        "    n_faces=N_FACES,\n",
        "    preprocess=preprocess\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS\n",
        ")"
      ],
      "metadata": {
        "id": "eTTBMnOqjkLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(PRETRAINED_MODEL_PATH):\n",
        "    encoder = resnet18(pretrained=False)\n",
        "    classifier = DeepfakeClassifier(encoder=encoder, in_channels=3*N_FACES, num_classes=1)\n",
        "    state = torch.load(PRETRAINED_MODEL_PATH, map_location=lambda storage, loc: storage)\n",
        "    classifier.load_state_dict(state['state_dict'])\n",
        "else:\n",
        "    encoder = resnet18(pretrained=True)\n",
        "    classifier = DeepfakeClassifier(encoder=encoder, in_channels=3*N_FACES, num_classes=1)\n",
        "\n",
        "classifier.to(device)\n",
        "classifier.train()"
      ],
      "metadata": {
        "id": "1tkJuoVpjn0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = FocalLoss()"
      ],
      "metadata": {
        "id": "LNS_gQYDjpfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = np.zeros(WARM_UP_EPOCHS + FINE_TUNE_EPOCHS)\n",
        "val_losses = np.zeros(WARM_UP_EPOCHS + FINE_TUNE_EPOCHS)\n",
        "loglosses = np.zeros(WARM_UP_EPOCHS + FINE_TUNE_EPOCHS)\n",
        "val_loglosses = np.zeros(WARM_UP_EPOCHS + FINE_TUNE_EPOCHS)\n",
        "f1_scores = np.zeros(WARM_UP_EPOCHS + FINE_TUNE_EPOCHS)\n",
        "val_f1_scores = np.zeros(WARM_UP_EPOCHS + FINE_TUNE_EPOCHS)\n",
        "\n",
        "if os.path.exists(PRETRAINED_MODEL_PATH):\n",
        "    best_val_loss = state['best_val_loss']\n",
        "else:\n",
        "    best_val_loss = 1e7\n",
        "\n",
        "if os.path.exists(PRETRAINED_MODEL_PATH):\n",
        "    best_val_logloss = state['best_val_logloss']\n",
        "else:\n",
        "    best_val_logloss = 1e7"
      ],
      "metadata": {
        "id": "P6C4LekSjrER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.freeze_middle_layers()\n",
        "warmup_optimizer = optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()), lr=WARM_UP_LR)\n",
        "if os.path.exists(PRETRAINED_MODEL_PATH) and 'warmup_optimizer' in state.keys():\n",
        "    warmup_optimizer.load_state_dict(state['warmup_optimizer'])"
      ],
      "metadata": {
        "id": "4QY-wwmXjsxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses[:WARM_UP_EPOCHS], val_losses[:WARM_UP_EPOCHS], \\\n",
        "loglosses[:WARM_UP_EPOCHS], val_loglosses[:WARM_UP_EPOCHS], \\\n",
        "f1_scores[:WARM_UP_EPOCHS], val_f1_scores[:WARM_UP_EPOCHS], \\\n",
        "best_val_loss, best_val_logloss, \\\n",
        "best_model_state_dict, best_optimizer_state_dict \\\n",
        "= train_the_model(\n",
        "    model=classifier,\n",
        "    criterion=criterion,\n",
        "    optimizer=warmup_optimizer,\n",
        "    epochs=WARM_UP_EPOCHS,\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    best_val_loss=best_val_loss,\n",
        "    best_val_logloss=best_val_logloss,\n",
        "    save_the_best_on='val_logloss'\n",
        ")\n",
        "\n",
        "# Save the best checkpoint.\n",
        "if best_model_state_dict is not None:\n",
        "    state = {\n",
        "        'state_dict': best_model_state_dict,\n",
        "        'warmup_optimizer': best_optimizer_state_dict,\n",
        "        'best_val_loss': best_val_loss,\n",
        "        'best_val_logloss': best_val_logloss\n",
        "    }\n",
        "    torch.save(state, SAVE_PATH)"
      ],
      "metadata": {
        "id": "4xG1FL1gjyV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_results(\n",
        "    losses=losses[:WARM_UP_EPOCHS],\n",
        "    val_losses=val_losses[:WARM_UP_EPOCHS],\n",
        "    loglosses=loglosses[:WARM_UP_EPOCHS],\n",
        "    val_loglosses=val_loglosses[:WARM_UP_EPOCHS],\n",
        "    f1_scores=f1_scores[:WARM_UP_EPOCHS],\n",
        "    val_f1_scores=val_f1_scores[:WARM_UP_EPOCHS]\n",
        ")"
      ],
      "metadata": {
        "id": "SgKlA8Aaj4x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.unfreeze_all_layers()\n"
      ],
      "metadata": {
        "id": "8nCqeKuKj6ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_optimizer = optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()), lr=FINE_TUNE_LR)\n",
        "if os.path.exists(PRETRAINED_MODEL_PATH) and 'finetune_optimizer' in state.keys() and WARM_UP_EPOCHS == 0:\n",
        "    finetune_optimizer.load_state_dict(state['finetune_optimizer'])"
      ],
      "metadata": {
        "id": "hQjJ0e9vlMMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses[WARM_UP_EPOCHS:WARM_UP_EPOCHS+FINE_TUNE_EPOCHS], val_losses[WARM_UP_EPOCHS:WARM_UP_EPOCHS+FINE_TUNE_EPOCHS], \\\n",
        "loglosses[WARM_UP_EPOCHS:WARM_UP_EPOCHS+FINE_TUNE_EPOCHS], val_loglosses[WARM_UP_EPOCHS:WARM_UP_EPOCHS+FINE_TUNE_EPOCHS], \\\n",
        "f1_scores[WARM_UP_EPOCHS:WARM_UP_EPOCHS+FINE_TUNE_EPOCHS], val_f1_scores[WARM_UP_EPOCHS:WARM_UP_EPOCHS+FINE_TUNE_EPOCHS], \\\n",
        "best_val_loss, best_val_logloss, \\\n",
        "best_model_state_dict, best_optimizer_state_dict \\\n",
        "= train_the_model(\n",
        "    model=classifier,\n",
        "    criterion=criterion,\n",
        "    optimizer=finetune_optimizer,\n",
        "    epochs=FINE_TUNE_EPOCHS,\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    best_val_loss=best_val_loss,\n",
        "    best_val_logloss=best_val_logloss,\n",
        "    save_the_best_on='val_logloss'\n",
        ")\n",
        "\n",
        "if best_model_state_dict is not None:\n",
        "    state = {\n",
        "        'state_dict': best_model_state_dict,\n",
        "        'finetune_optimizer': best_optimizer_state_dict,\n",
        "        'best_val_loss': best_val_loss,\n",
        "        'best_val_logloss': best_val_logloss\n",
        "    }\n",
        "\n",
        "    torch.save(state, SAVE_PATH)"
      ],
      "metadata": {
        "id": "a_y_iSFplNa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_results(\n",
        "    losses=losses,\n",
        "    val_losses=val_losses,\n",
        "    loglosses=loglosses,\n",
        "    val_loglosses=val_loglosses,\n",
        "    f1_scores=f1_scores,\n",
        "    val_f1_scores=val_f1_scores\n",
        ")"
      ],
      "metadata": {
        "id": "rI5EvG2YlZGs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}